2023-05-22 11:07:38,835:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'value': 1}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'value': 'max'}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 11:07:39,665:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 11:14:17,677:ERROR:Task was destroyed but it is pending!
task: <Task pending name='Task-2' coro=<Kernel.poll_control_queue() running at /home/liuxr/miniconda3/lib/python3.10/site-packages/ipykernel/kernelbase.py:281> wait_for=<Future finished result=<Future at 0x...state=pending>> cb=[_chain_future.<locals>._call_set_state() at /home/liuxr/miniconda3/lib/python3.10/asyncio/futures.py:392]>
2023-05-22 11:15:44,680:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'value': 1}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'value': 'max'}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 11:15:45,484:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 11:16:10,838:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'value': 1}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'value': 'max'}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 11:16:11,590:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 11:20:47,326:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'value': 1}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'value': 'max'}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 11:20:47,993:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 11:21:09,480:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'value': 1}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'value': 'max'}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 11:21:10,129:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 11:22:07,892:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'value': 1}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'value': 'max'}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 11:22:08,873:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 11:23:50,718:INFO:Epoch: 1, Training Loss: 1.6242
2023-05-22 11:23:55,412:INFO:Epoch: 1, Validation Loss: 1.4048
2023-05-22 11:24:18,476:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'value': 1}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'value': 'max'}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 11:24:19,363:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 11:25:18,087:INFO:Epoch: 1, Training Loss: 1.7843
2023-05-22 11:25:21,253:INFO:Epoch: 1, Validation Loss: 1.3336
2023-05-22 11:25:39,738:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'value': 1}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'value': 'max'}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 11:25:40,343:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 11:26:40,729:INFO:Epoch: 1, Training Loss: 1.4902
2023-05-22 11:26:44,266:INFO:Epoch: 1, Validation Loss: 1.2871
2023-05-22 11:27:05,042:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'value': 1}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'value': 'max'}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 11:27:05,677:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 11:28:40,131:INFO:Epoch: 1, Training Loss: 4.7534
2023-05-22 11:28:45,186:INFO:Epoch: 1, Validation Loss: 1.9207
2023-05-22 11:30:13,119:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'value': 10}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'value': 'max'}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 11:30:13,670:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 11:31:34,535:INFO:Epoch: 10, Training Loss: 1.4690
2023-05-22 11:31:39,008:INFO:Epoch: 10, Validation Loss: 1.3798
2023-05-22 11:33:12,153:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'value': 10}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'value': 'max'}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 11:33:13,034:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 11:34:33,086:INFO:Epoch: 0, Training Loss: 36.4952
2023-05-22 11:34:37,290:INFO:Epoch: 0, Validation Loss: 1.8477
2023-05-22 11:35:50,188:INFO:Epoch: 1, Training Loss: 1.7460
2023-05-22 11:35:52,934:INFO:Epoch: 1, Validation Loss: 1.8113
2023-05-22 11:36:48,090:INFO:Epoch: 2, Training Loss: 1.7304
2023-05-22 11:36:50,803:INFO:Epoch: 2, Validation Loss: 1.6807
2023-05-22 11:37:55,084:INFO:Epoch: 3, Training Loss: 1.7277
2023-05-22 11:37:57,643:INFO:Epoch: 3, Validation Loss: 1.7243
2023-05-22 11:39:04,715:INFO:Epoch: 4, Training Loss: 1.7300
2023-05-22 11:39:07,226:INFO:Epoch: 4, Validation Loss: 1.7149
2023-05-22 11:39:54,820:INFO:Epoch: 5, Training Loss: 1.7593
2023-05-22 11:39:57,264:INFO:Epoch: 5, Validation Loss: 1.8039
2023-05-22 11:40:45,112:INFO:Epoch: 6, Training Loss: 1.7613
2023-05-22 11:40:47,598:INFO:Epoch: 6, Validation Loss: 2.1049
2023-05-22 11:41:35,975:INFO:Epoch: 7, Training Loss: 1.9212
2023-05-22 11:41:38,494:INFO:Epoch: 7, Validation Loss: 2.0339
2023-05-22 11:42:25,627:INFO:Epoch: 8, Training Loss: 2.0160
2023-05-22 11:42:28,313:INFO:Epoch: 8, Validation Loss: 2.0565
2023-05-22 11:43:17,194:INFO:Epoch: 9, Training Loss: 2.0171
2023-05-22 11:43:20,417:INFO:Epoch: 9, Validation Loss: 2.0367
2023-05-22 11:43:44,136:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'value': 10}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'value': 'max'}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 11:43:45,284:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 11:45:19,335:INFO:Epoch: 0, Training Loss: 3.1018
2023-05-22 11:45:23,418:INFO:Epoch: 0, Validation Loss: 1.4402
2023-05-22 11:46:25,780:INFO:Epoch: 1, Training Loss: 1.4242
2023-05-22 11:46:28,968:INFO:Epoch: 1, Validation Loss: 1.4978
2023-05-22 11:47:35,912:INFO:Epoch: 2, Training Loss: 1.4348
2023-05-22 11:47:39,382:INFO:Epoch: 2, Validation Loss: 1.4052
2023-05-22 11:48:42,237:INFO:Epoch: 3, Training Loss: 2.2261
2023-05-22 11:48:45,287:INFO:Epoch: 3, Validation Loss: 2.2880
2023-05-22 11:49:48,250:INFO:Epoch: 4, Training Loss: 2.2765
2023-05-22 11:49:51,226:INFO:Epoch: 4, Validation Loss: 2.2894
2023-05-22 11:50:53,705:INFO:Epoch: 5, Training Loss: 2.2767
2023-05-22 11:50:56,835:INFO:Epoch: 5, Validation Loss: 2.2879
2023-05-22 11:52:00,529:INFO:Epoch: 6, Training Loss: 2.2761
2023-05-22 11:52:03,690:INFO:Epoch: 6, Validation Loss: 2.2922
2023-05-22 11:53:05,853:INFO:Epoch: 7, Training Loss: 2.2768
2023-05-22 11:53:08,935:INFO:Epoch: 7, Validation Loss: 2.2897
2023-05-22 11:54:16,693:INFO:Epoch: 8, Training Loss: 2.2765
2023-05-22 11:54:19,739:INFO:Epoch: 8, Validation Loss: 2.2917
2023-05-22 11:55:20,877:INFO:Epoch: 9, Training Loss: 2.2765
2023-05-22 11:55:23,955:INFO:Epoch: 9, Validation Loss: 2.3064
2023-05-22 11:55:51,205:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'value': 10}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'value': 'max'}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 11:55:51,723:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 11:56:43,507:INFO:Epoch: 0, Training Loss: 9.4763
2023-05-22 11:56:46,591:INFO:Epoch: 0, Validation Loss: 1.3719
2023-05-22 11:57:32,263:INFO:Epoch: 1, Training Loss: 1.3017
2023-05-22 11:57:34,324:INFO:Epoch: 1, Validation Loss: 1.2971
2023-05-22 11:58:16,557:INFO:Epoch: 2, Training Loss: 1.3050
2023-05-22 11:58:20,091:INFO:Epoch: 2, Validation Loss: 1.2761
2023-05-22 11:58:59,374:INFO:Epoch: 3, Training Loss: 1.2456
2023-05-22 11:59:01,460:INFO:Epoch: 3, Validation Loss: 1.1900
2023-05-22 11:59:41,122:INFO:Epoch: 4, Training Loss: 1.2703
2023-05-22 11:59:43,427:INFO:Epoch: 4, Validation Loss: 1.3812
2023-05-22 12:00:22,264:INFO:Epoch: 5, Training Loss: 1.3082
2023-05-22 12:00:24,329:INFO:Epoch: 5, Validation Loss: 1.4521
2023-05-22 12:01:02,973:INFO:Epoch: 6, Training Loss: 1.3024
2023-05-22 12:01:04,991:INFO:Epoch: 6, Validation Loss: 1.3692
2023-05-22 12:01:44,570:INFO:Epoch: 7, Training Loss: 1.2944
2023-05-22 12:01:46,711:INFO:Epoch: 7, Validation Loss: 1.2884
2023-05-22 12:02:28,210:INFO:Epoch: 8, Training Loss: 1.2920
2023-05-22 12:02:30,292:INFO:Epoch: 8, Validation Loss: 1.2987
2023-05-22 12:03:11,419:INFO:Epoch: 9, Training Loss: 1.2950
2023-05-22 12:03:13,529:INFO:Epoch: 9, Validation Loss: 1.2926
2023-05-22 12:03:33,099:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'value': 10}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'value': 'max'}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 12:03:33,749:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 12:04:32,946:INFO:Epoch: 0, Training Loss: 5.9353
2023-05-22 12:04:36,209:INFO:Epoch: 0, Validation Loss: 1.4714
2023-05-22 12:05:20,901:INFO:Epoch: 1, Training Loss: 1.3170
2023-05-22 12:05:23,399:INFO:Epoch: 1, Validation Loss: 1.3068
2023-05-22 12:06:09,286:INFO:Epoch: 2, Training Loss: 1.3120
2023-05-22 12:06:11,620:INFO:Epoch: 2, Validation Loss: 1.3394
2023-05-22 12:06:56,306:INFO:Epoch: 3, Training Loss: 1.3172
2023-05-22 12:06:58,585:INFO:Epoch: 3, Validation Loss: 1.2944
2023-05-22 12:07:43,632:INFO:Epoch: 4, Training Loss: 1.3258
2023-05-22 12:07:46,147:INFO:Epoch: 4, Validation Loss: 1.3655
2023-05-22 12:08:29,987:INFO:Epoch: 5, Training Loss: 1.3227
2023-05-22 12:08:32,300:INFO:Epoch: 5, Validation Loss: 1.3436
2023-05-22 12:09:15,008:INFO:Epoch: 6, Training Loss: 1.3207
2023-05-22 12:09:17,310:INFO:Epoch: 6, Validation Loss: 1.3633
2023-05-22 12:10:00,026:INFO:Epoch: 7, Training Loss: 1.3309
2023-05-22 12:10:02,398:INFO:Epoch: 7, Validation Loss: 1.2972
2023-05-22 12:10:45,026:INFO:Epoch: 8, Training Loss: 1.3417
2023-05-22 12:10:47,368:INFO:Epoch: 8, Validation Loss: 1.4327
2023-05-22 12:11:30,659:INFO:Epoch: 9, Training Loss: 1.3783
2023-05-22 12:11:32,912:INFO:Epoch: 9, Validation Loss: 1.3849
2023-05-22 13:21:31,195:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'values': [20, 40, 60, 80]}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'values': ['max', 'mean']}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 13:21:31,727:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 13:22:37,876:INFO:{'method': 'random', 'metric': {'goal': 'minimize', 'name': 'val_loss'}, 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values', 'max': 256, 'min': 16, 'q': 8}, 'criterion': {'value': 'MSELoss()'}, 'epochs': {'values': [20, 40, 60, 80]}, 'hidden_dim_1': {'value': 64}, 'hidden_dim_2': {'value': 128}, 'hidden_dim_3': {'value': 32}, 'in_channels': {'value': 11}, 'lr': {'distribution': 'uniform', 'max': 0.1, 'min': 0}, 'nnconv_aggr': {'values': ['max', 'mean', 'add']}, 'optimizer': {'value': 'adam'}, 'out_channels': {'value': 1}}}
2023-05-22 13:22:39,158:INFO:GNNModel(
  (conv1): NNConv(11, 64, aggr=max, nn=Sequential(
    (0): Linear(in_features=5, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=704, bias=True)
  ))
  (global_pool): MaxAggregation()
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=32, out_features=1, bias=True)
)
2023-05-22 13:22:45,812:INFO:Epoch: 0, Training Loss: 31.0896
2023-05-22 13:22:55,727:INFO:Epoch: 0, Validation Loss: 1.3463
2023-05-22 13:24:29,164:INFO:Epoch: 1, Training Loss: 1.3378
2023-05-22 13:24:35,090:INFO:Epoch: 1, Validation Loss: 1.2909
2023-05-22 13:25:57,607:INFO:Epoch: 0, Training Loss: 32.6343
2023-05-22 13:26:07,361:INFO:Epoch: 0, Validation Loss: 1.7628
2023-05-22 13:26:07,633:INFO:Epoch: 2, Training Loss: 1.3236
2023-05-22 13:26:12,513:INFO:Epoch: 2, Validation Loss: 1.2994
2023-05-22 13:27:30,815:INFO:Epoch: 3, Training Loss: 1.3106
2023-05-22 13:27:35,083:INFO:Epoch: 3, Validation Loss: 1.2832
2023-05-22 13:27:55,967:INFO:Epoch: 1, Training Loss: 1.5608
2023-05-22 13:28:05,611:INFO:Epoch: 1, Validation Loss: 1.5401
2023-05-22 13:28:46,823:INFO:Epoch: 4, Training Loss: 1.3062
2023-05-22 13:28:50,996:INFO:Epoch: 4, Validation Loss: 1.2780
2023-05-22 13:30:04,752:INFO:Epoch: 5, Training Loss: 1.3091
2023-05-22 13:30:09,355:INFO:Epoch: 5, Validation Loss: 1.2786
2023-05-22 13:30:20,323:INFO:Epoch: 2, Training Loss: 1.5587
2023-05-22 13:30:25,730:INFO:Epoch: 2, Validation Loss: 1.5635
2023-05-22 13:31:38,106:INFO:Epoch: 6, Training Loss: 1.3082
2023-05-22 13:31:43,222:INFO:Epoch: 6, Validation Loss: 1.2988
2023-05-22 13:32:15,232:INFO:Epoch: 3, Training Loss: 1.5730
2023-05-22 13:32:21,321:INFO:Epoch: 3, Validation Loss: 1.6138
2023-05-22 13:33:14,447:INFO:Epoch: 7, Training Loss: 1.3119
2023-05-22 13:33:19,536:INFO:Epoch: 7, Validation Loss: 1.2952
2023-05-22 13:34:08,731:INFO:Epoch: 4, Training Loss: 1.5763
2023-05-22 13:34:17,371:INFO:Epoch: 4, Validation Loss: 1.5326
2023-05-22 13:34:56,882:INFO:Epoch: 8, Training Loss: 1.3123
2023-05-22 13:35:02,373:INFO:Epoch: 8, Validation Loss: 1.3147
2023-05-22 13:36:09,865:INFO:Epoch: 5, Training Loss: 1.5841
2023-05-22 13:36:16,972:INFO:Epoch: 5, Validation Loss: 1.5312
2023-05-22 13:36:40,606:INFO:Epoch: 9, Training Loss: 1.3168
2023-05-22 13:36:46,044:INFO:Epoch: 9, Validation Loss: 1.3282
2023-05-22 13:38:14,207:INFO:Epoch: 6, Training Loss: 1.5858
2023-05-22 13:38:21,201:INFO:Epoch: 6, Validation Loss: 1.5469
2023-05-22 13:38:29,849:INFO:Epoch: 10, Training Loss: 1.3104
2023-05-22 13:38:36,680:INFO:Epoch: 10, Validation Loss: 1.2750
2023-05-22 13:40:18,404:INFO:Epoch: 11, Training Loss: 1.3109
2023-05-22 13:40:20,997:INFO:Epoch: 7, Training Loss: 1.7512
2023-05-22 13:40:23,922:INFO:Epoch: 11, Validation Loss: 1.3215
2023-05-22 13:40:27,109:INFO:Epoch: 7, Validation Loss: 2.0919
2023-05-22 13:42:09,633:INFO:Epoch: 12, Training Loss: 1.3342
2023-05-22 13:42:18,537:INFO:Epoch: 12, Validation Loss: 1.4375
2023-05-22 13:42:27,982:INFO:Epoch: 8, Training Loss: 2.0923
2023-05-22 13:42:33,777:INFO:Epoch: 8, Validation Loss: 2.0910
2023-05-22 13:44:10,470:INFO:Epoch: 13, Training Loss: 1.3158
2023-05-22 13:44:18,320:INFO:Epoch: 13, Validation Loss: 1.3437
