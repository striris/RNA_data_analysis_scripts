{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "249c1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import QM9\n",
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn import GRU, Linear, ReLU, Sequential\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import NNConv, Set2Set, MessagePassing, global_mean_pool, aggr\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdde730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 0 # the first property is the one to be predicted\n",
    "\n",
    "class TargetTransform:\n",
    "    def __call__(self, data):\n",
    "        # Specify target.\n",
    "        data.y = data.y[:, target]\n",
    "        return data\n",
    "\n",
    "path = './datasets/QM9'\n",
    "transform = T.Compose([TargetTransform(), T.Distance(norm=False)]) # add the distance into edge attributes\n",
    "dataset = QM9(path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab43c480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After transformation:\n",
      "Data(x=[5, 11], edge_index=[2, 8], edge_attr=[8, 5], y=[1], pos=[5, 3], idx=[1], name='gdb_1', z=[5])\n",
      "tensor([[0, 0, 0, 0, 1, 2, 3, 4],\n",
      "        [1, 2, 3, 4, 0, 0, 0, 0]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 1.0919],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 1.0919],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 1.0919],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 1.0919],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 1.0919],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 1.0919],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 1.0919],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 1.0919]])\n",
      "Number of nodes: 5\n",
      "Number of edges: 8\n",
      "Average node degree: 1.60\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "print('After transformation:')\n",
    "print(data)\n",
    "print(data.edge_index)\n",
    "print(data.edge_attr)\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c547af",
   "metadata": {},
   "source": [
    "By defining the message() and update() functions, you control how information is propagated through the graph and how nodes update their representations based on the received messages. These functions enable the GNN to learn from the graph structure and capture useful information for the prediction task.\n",
    "\n",
    "During the forward() pass, the GNN iteratively performs message passing and aggregation steps across the graph, combining information from neighboring nodes to update each node's representation. The output of the forward() function provides the final representations that can be further processed or used for downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b0b55c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gnn_details'\n",
    "config = {\n",
    "    \"in_channels\": 3,\n",
    "    \"out_channels\": 1,\n",
    "    \"hidden_dim_1\": 4,\n",
    "    \"hidden_dim_2\": 5,\n",
    "    \"hidden_dim_3\": 32,\n",
    "    \"lr\": 0.001,\n",
    "    \"batch_size\": 20,\n",
    "    \"num_epochs\": 3,\n",
    "    \"criterion\": nn.MSELoss(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1febbf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split datasets.\n",
    "torch.manual_seed(12345)\n",
    "dataset = dataset.shuffle()\n",
    "test_dataset = dataset[:10000]\n",
    "val_dataset = dataset[10000:20000]\n",
    "train_dataset = dataset[20000:]\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False) #10000\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False) #10000\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True) #110831"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac7120da",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[0,4,2], [1,3,1], [2,-1,1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd6e0ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  4.,  2.],\n",
       "        [ 1.,  3.,  1.],\n",
       "        [ 2., -1.,  1.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e035820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the customized message passing layer\n",
    "class GNN(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GNN, self).__init__(aggr='mean')\n",
    "        self.lin = nn.Linear(in_channels, out_channels)\n",
    "        self.lin2 = nn.Linear(5, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        print('forward')\n",
    "        print('x',x)\n",
    "        print('x.shape',x.shape)\n",
    "        print('edge_index',edge_index)\n",
    "        print('edge_index.shape',edge_index.shape)\n",
    "        return self.propagate(edge_index, edge_attr=edge_attr,x=x)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        print('message')\n",
    "        print('x_j',x_j)\n",
    "        print('x_j.shape',x_j.shape) # num_edges * node_features\n",
    "        print('lin(x_j)',self.lin(x_j))\n",
    "        print('lin(x_j).shape',self.lin(x_j).shape) # num_edges * 64\n",
    "        #print('edge_attr ',self.lin2(edge_attr)) \n",
    "        #print('edge_attr.shape ',self.lin2(edge_attr).shape) # num_edges * 64\n",
    "        return self.lin(x_j)#+self.lin2(edge_attr) # can use different operators and assign them different weights\n",
    "        #represents the feature representations of the neighboring nodes.\n",
    "    \n",
    "    def update(self, aggr_out, x):\n",
    "        print('update')\n",
    "        print('x', x)\n",
    "        print('lin(x)', self.lin(x))\n",
    "        print('aggr_out',aggr_out)\n",
    "        print('aggr_out.shape',aggr_out.shape)\n",
    "        print('lin(x)+aggr_out',self.lin(x)+ aggr_out)\n",
    "        return aggr_out+self.lin(x)\n",
    "\n",
    "# Define the GNN-based model\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim_1, hidden_dim_2, hidden_dim_3, out_channels):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.gnn = GNN(in_channels, hidden_dim_1)\n",
    "        self.gnn2 = GNN(hidden_dim_1, hidden_dim_2)\n",
    "        # Use a global sort aggregation:\n",
    "        self.global_pool = aggr.MeanAggregation()\n",
    "        self.fc1 = nn.Linear(hidden_dim_2, hidden_dim_3)\n",
    "        self.fc2 = nn.Linear(hidden_dim_3, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        x = self.gnn(x, edge_index, edge_attr).relu()\n",
    "        x = self.gnn2(x, edge_index, edge_attr).relu()\n",
    "        x = self.global_pool(x,batch)\n",
    "        x = self.fc1(x).relu()\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "266ab8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNModel(\n",
      "  (gnn): GNN()\n",
      "  (gnn2): GNN()\n",
      "  (global_pool): MeanAggregation()\n",
      "  (fc1): Linear(in_features=5, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GNNModel(config[\"in_channels\"], config[\"hidden_dim_1\"], config[\"hidden_dim_2\"], config[\"hidden_dim_3\"], config[\"out_channels\"])\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d535e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n",
      "x tensor([[ 0.,  4.,  2.],\n",
      "        [ 1.,  3.,  1.],\n",
      "        [ 2., -1.,  1.]])\n",
      "x.shape torch.Size([3, 3])\n",
      "edge_index tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "edge_index.shape torch.Size([2, 4])\n",
      "message\n",
      "x_j tensor([[ 0.,  4.,  2.],\n",
      "        [ 1.,  3.,  1.],\n",
      "        [ 1.,  3.,  1.],\n",
      "        [ 2., -1.,  1.]])\n",
      "x_j.shape torch.Size([4, 3])\n",
      "lin(x_j) tensor([[ 1.8508,  0.8710, -0.9157, -1.1656],\n",
      "        [ 1.1132,  0.1986, -0.9161, -1.3484],\n",
      "        [ 1.1132,  0.1986, -0.9161, -1.3484],\n",
      "        [ 0.2837,  0.1969,  0.9099,  0.1637]], grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape torch.Size([4, 4])\n",
      "update\n",
      "x tensor([[ 0.,  4.,  2.],\n",
      "        [ 1.,  3.,  1.],\n",
      "        [ 2., -1.,  1.]])\n",
      "lin(x) tensor([[ 1.8508,  0.8710, -0.9157, -1.1656],\n",
      "        [ 1.1132,  0.1986, -0.9161, -1.3484],\n",
      "        [ 0.2837,  0.1969,  0.9099,  0.1637]], grad_fn=<AddmmBackward0>)\n",
      "aggr_out tensor([[ 1.1132,  0.1986, -0.9161, -1.3484],\n",
      "        [ 1.0673,  0.5340, -0.0029, -0.5010],\n",
      "        [ 1.1132,  0.1986, -0.9161, -1.3484]], grad_fn=<DivBackward0>)\n",
      "aggr_out.shape torch.Size([3, 4])\n",
      "lin(x)+aggr_out tensor([[ 2.9640,  1.0696, -1.8317, -2.5141],\n",
      "        [ 2.1804,  0.7325, -0.9189, -1.8494],\n",
      "        [ 1.3969,  0.3955, -0.0061, -1.1847]], grad_fn=<AddBackward0>)\n",
      "forward\n",
      "x tensor([[2.9640, 1.0696, 0.0000, 0.0000],\n",
      "        [2.1804, 0.7325, 0.0000, 0.0000],\n",
      "        [1.3969, 0.3955, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n",
      "x.shape torch.Size([3, 4])\n",
      "edge_index tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "edge_index.shape torch.Size([2, 4])\n",
      "message\n",
      "x_j tensor([[2.9640, 1.0696, 0.0000, 0.0000],\n",
      "        [2.1804, 0.7325, 0.0000, 0.0000],\n",
      "        [2.1804, 0.7325, 0.0000, 0.0000],\n",
      "        [1.3969, 0.3955, 0.0000, 0.0000]], grad_fn=<IndexSelectBackward0>)\n",
      "x_j.shape torch.Size([4, 4])\n",
      "lin(x_j) tensor([[ 0.9572, -1.1523, -0.4216,  1.4454, -0.6888],\n",
      "        [ 0.6922, -0.8333, -0.4506,  1.1793, -0.4108],\n",
      "        [ 0.6922, -0.8333, -0.4506,  1.1793, -0.4108],\n",
      "        [ 0.4273, -0.5144, -0.4796,  0.9133, -0.1327]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape torch.Size([4, 5])\n",
      "update\n",
      "x tensor([[2.9640, 1.0696, 0.0000, 0.0000],\n",
      "        [2.1804, 0.7325, 0.0000, 0.0000],\n",
      "        [1.3969, 0.3955, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n",
      "lin(x) tensor([[ 0.9572, -1.1523, -0.4216,  1.4454, -0.6888],\n",
      "        [ 0.6922, -0.8333, -0.4506,  1.1793, -0.4108],\n",
      "        [ 0.4273, -0.5144, -0.4796,  0.9133, -0.1327]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "aggr_out tensor([[ 0.6922, -0.8333, -0.4506,  1.1793, -0.4108],\n",
      "        [ 0.6922, -0.8333, -0.4506,  1.1793, -0.4108],\n",
      "        [ 0.6922, -0.8333, -0.4506,  1.1793, -0.4108]], grad_fn=<DivBackward0>)\n",
      "aggr_out.shape torch.Size([3, 5])\n",
      "lin(x)+aggr_out tensor([[ 1.6494, -1.9856, -0.8721,  2.6247, -1.0996],\n",
      "        [ 1.3845, -1.6667, -0.9011,  2.3586, -0.8216],\n",
      "        [ 1.1195, -1.3477, -0.9301,  2.0926, -0.5435]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = model(data).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "025985e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape  torch.Size([349, 11])\n",
      "edge_index.shape  torch.Size([2, 736])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 2.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 2.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 2.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([736, 11])\n",
      "lin(x_j)  tensor([[ 1.5753, -0.8763,  1.1009,  ...,  0.5212,  0.6490,  2.5236],\n",
      "        [ 1.5753, -0.8763,  1.1009,  ...,  0.5212,  0.6490,  2.5236],\n",
      "        [ 1.5753, -0.8763,  1.1009,  ...,  0.5212,  0.6490,  2.5236],\n",
      "        ...,\n",
      "        [ 0.6298, -0.4255,  0.4990,  ...,  0.2184,  0.3819,  0.3936],\n",
      "        [ 0.6298, -0.4255,  0.4990,  ...,  0.2184,  0.3819,  0.3936],\n",
      "        [ 0.6298, -0.4255,  0.4990,  ...,  0.2184,  0.3819,  0.3936]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([736, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.3615, -0.7446,  0.8518,  ...,  0.1454,  0.7390,  1.4452],\n",
      "        [ 1.6736, -0.8587,  1.0215,  ...,  0.2787,  0.7999,  2.3014],\n",
      "        [ 1.8588, -0.9656,  1.1329,  ...,  0.2361,  0.9103,  2.4546],\n",
      "        ...,\n",
      "        [ 1.5753, -0.8763,  1.1009,  ...,  0.5212,  0.6490,  2.5236],\n",
      "        [ 1.5753, -0.8763,  1.1009,  ...,  0.5212,  0.6490,  2.5236],\n",
      "        [ 2.4145, -1.2862,  1.4670,  ...,  0.1084,  1.2415,  2.9144]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([349, 64])\n",
      "x.shape  torch.Size([358, 11])\n",
      "edge_index.shape  torch.Size([2, 752])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([752, 11])\n",
      "lin(x_j)  tensor([[ 1.4780, -0.8939,  1.1814,  ...,  0.7648,  0.4992,  2.7468],\n",
      "        [ 1.4780, -0.8939,  1.1814,  ...,  0.7648,  0.4992,  2.7468],\n",
      "        [ 1.4780, -0.8939,  1.1814,  ...,  0.7648,  0.4992,  2.7468],\n",
      "        ...,\n",
      "        [ 0.6301, -0.4255,  0.4994,  ...,  0.2187,  0.3823,  0.3939],\n",
      "        [ 0.6301, -0.4255,  0.4994,  ...,  0.2187,  0.3823,  0.3939],\n",
      "        [ 0.6301, -0.4255,  0.4994,  ...,  0.2187,  0.3823,  0.3939]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([752, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.9159, -0.5294,  0.6104,  ...,  0.1734,  0.5247,  0.8155],\n",
      "        [ 1.7863, -0.9788,  1.1938,  ...,  0.4192,  0.7985,  2.6225],\n",
      "        [ 1.3869, -0.7402,  0.8329,  ...,  0.0856,  0.7777,  1.3906],\n",
      "        ...,\n",
      "        [ 1.6747, -0.8587,  1.0228,  ...,  0.2798,  0.8011,  2.3026],\n",
      "        [ 1.5763, -0.8763,  1.1021,  ...,  0.5223,  0.6502,  2.5247],\n",
      "        [ 1.5763, -0.8763,  1.1021,  ...,  0.5223,  0.6502,  2.5247]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([358, 64])\n",
      "x.shape  torch.Size([339, 11])\n",
      "edge_index.shape  torch.Size([2, 716])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([716, 11])\n",
      "lin(x_j)  tensor([[ 2.5155, -1.2686,  1.3908,  ..., -0.1316,  1.3955,  2.6952],\n",
      "        [ 1.7738, -0.8411,  0.9443,  ...,  0.0381,  0.9529,  2.0812],\n",
      "        [ 1.7738, -0.8411,  0.9443,  ...,  0.0381,  0.9529,  2.0812],\n",
      "        ...,\n",
      "        [ 0.6303, -0.4255,  0.4995,  ...,  0.2188,  0.3824,  0.3940],\n",
      "        [ 0.6303, -0.4255,  0.4995,  ...,  0.2188,  0.3824,  0.3940],\n",
      "        [ 0.6303, -0.4255,  0.4995,  ...,  0.2188,  0.3824,  0.3940]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([716, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.7738, -0.8411,  0.9443,  ...,  0.0381,  0.9529,  2.0812],\n",
      "        [ 2.2354, -1.1320,  1.2683,  ...,  0.0058,  1.1976,  2.5645],\n",
      "        [ 1.7245, -0.8499,  0.9839,  ...,  0.1592,  0.8773,  2.1922],\n",
      "        ...,\n",
      "        [ 1.5768, -0.8763,  1.1026,  ...,  0.5227,  0.6507,  2.5251],\n",
      "        [ 1.6753, -0.8587,  1.0234,  ...,  0.2804,  0.8018,  2.3032],\n",
      "        [ 1.6753, -0.8587,  1.0234,  ...,  0.2804,  0.8018,  2.3032]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([339, 64])\n",
      "x.shape  torch.Size([373, 11])\n",
      "edge_index.shape  torch.Size([2, 770])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([770, 11])\n",
      "lin(x_j)  tensor([[ 1.4781, -0.8939,  1.1816,  ...,  0.7648,  0.4994,  2.7470],\n",
      "        [ 1.4781, -0.8939,  1.1816,  ...,  0.7648,  0.4994,  2.7470],\n",
      "        [ 1.4781, -0.8939,  1.1816,  ...,  0.7648,  0.4994,  2.7470],\n",
      "        ...,\n",
      "        [ 0.6303, -0.4255,  0.4996,  ...,  0.2188,  0.3824,  0.3941],\n",
      "        [ 0.6303, -0.4255,  0.4996,  ...,  0.2188,  0.3824,  0.3941],\n",
      "        [ 0.6303, -0.4255,  0.4996,  ...,  0.2188,  0.3824,  0.3941]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([770, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.0611, -0.6675,  0.7656,  ...,  0.2375,  0.5702,  0.9176],\n",
      "        [ 1.2942, -0.7202,  0.8753,  ...,  0.3407,  0.6118,  1.7409],\n",
      "        [ 2.3866, -1.3876,  1.5376,  ...,  0.2127,  1.1840,  2.4145],\n",
      "        ...,\n",
      "        [ 1.4781, -0.8939,  1.1816,  ...,  0.7648,  0.4994,  2.7470],\n",
      "        [ 1.4781, -0.8939,  1.1816,  ...,  0.7648,  0.4994,  2.7470],\n",
      "        [ 1.4781, -0.8939,  1.1816,  ...,  0.7648,  0.4994,  2.7470]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([373, 64])\n",
      "x.shape  torch.Size([369, 11])\n",
      "edge_index.shape  torch.Size([2, 778])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 2.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 2.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 2.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([778, 11])\n",
      "lin(x_j)  tensor([[ 1.5771, -0.8763,  1.1030,  ...,  0.5229,  0.6510,  2.5255],\n",
      "        [ 1.5771, -0.8763,  1.1030,  ...,  0.5229,  0.6510,  2.5255],\n",
      "        [ 1.5771, -0.8763,  1.1030,  ...,  0.5229,  0.6510,  2.5255],\n",
      "        ...,\n",
      "        [ 0.6304, -0.4255,  0.4997,  ...,  0.2188,  0.3826,  0.3942],\n",
      "        [ 0.6304, -0.4255,  0.4997,  ...,  0.2188,  0.3826,  0.3942],\n",
      "        [ 0.6304, -0.4255,  0.4997,  ...,  0.2188,  0.3826,  0.3942]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([778, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.3476, -0.7714,  0.8775,  ...,  0.1928,  0.7135,  1.3401],\n",
      "        [ 1.3274, -0.7143,  0.8494,  ...,  0.2602,  0.6626,  1.6673],\n",
      "        [ 1.7963, -1.0012,  1.1989,  ...,  0.4053,  0.8099,  2.4611],\n",
      "        ...,\n",
      "        [ 1.4782, -0.8939,  1.1817,  ...,  0.7648,  0.4995,  2.7471],\n",
      "        [ 1.4782, -0.8939,  1.1817,  ...,  0.7648,  0.4995,  2.7471],\n",
      "        [ 1.4782, -0.8939,  1.1817,  ...,  0.7648,  0.4995,  2.7471]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([369, 64])\n",
      "x.shape  torch.Size([352, 11])\n",
      "edge_index.shape  torch.Size([2, 728])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([728, 11])\n",
      "lin(x_j)  tensor([[ 2.5176, -1.2686,  1.3932,  ..., -0.1303,  1.3979,  2.6975],\n",
      "        [ 2.5176, -1.2686,  1.3932,  ..., -0.1303,  1.3979,  2.6975],\n",
      "        [ 2.4545, -1.3759,  1.4874,  ...,  0.0534,  1.2873,  2.2689],\n",
      "        ...,\n",
      "        [ 0.6303, -0.4255,  0.4995,  ...,  0.2186,  0.3824,  0.3940],\n",
      "        [ 0.6303, -0.4255,  0.4995,  ...,  0.2186,  0.3824,  0.3940],\n",
      "        [ 0.6303, -0.4255,  0.4995,  ...,  0.2186,  0.3824,  0.3940]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([728, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 2.1147, -1.1085,  1.2165,  ...,  0.0461,  1.1207,  2.1757],\n",
      "        [ 2.4861, -1.3222,  1.4403,  ..., -0.0385,  1.3426,  2.4832],\n",
      "        [ 2.1147, -1.1085,  1.2165,  ...,  0.0461,  1.1207,  2.1757],\n",
      "        ...,\n",
      "        [ 1.6758, -0.8587,  1.0240,  ...,  0.2806,  0.8024,  2.3037],\n",
      "        [ 2.2563, -1.4110,  1.6443,  ...,  0.5369,  0.9836,  2.7115],\n",
      "        [ 2.2563, -1.4110,  1.6443,  ...,  0.5369,  0.9836,  2.7115]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([352, 64])\n",
      "x.shape  torch.Size([356, 11])\n",
      "edge_index.shape  torch.Size([2, 732])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 1.,  ..., 0., 0., 2.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 2.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 2.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([732, 11])\n",
      "lin(x_j)  tensor([[ 2.2562, -1.4110,  1.6442,  ...,  0.5368,  0.9835,  2.7114],\n",
      "        [ 2.2562, -1.4110,  1.6442,  ...,  0.5368,  0.9835,  2.7114],\n",
      "        [ 2.2562, -1.4110,  1.6442,  ...,  0.5368,  0.9835,  2.7114],\n",
      "        ...,\n",
      "        [ 0.6301, -0.4255,  0.4993,  ...,  0.2184,  0.3822,  0.3938],\n",
      "        [ 0.6301, -0.4255,  0.4993,  ...,  0.2184,  0.3822,  0.3938],\n",
      "        [ 0.6301, -0.4255,  0.4993,  ...,  0.2184,  0.3822,  0.3938]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([732, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.0116, -0.5640,  0.6480,  ...,  0.1584,  0.5728,  0.9566],\n",
      "        [ 1.9021, -1.0370,  1.2043,  ...,  0.2851,  0.9131,  2.3656],\n",
      "        [ 1.5868, -0.8867,  1.0036,  ...,  0.1841,  0.8239,  1.6555],\n",
      "        ...,\n",
      "        [ 1.6754, -0.8587,  1.0235,  ...,  0.2800,  0.8019,  2.3032],\n",
      "        [ 1.6754, -0.8587,  1.0235,  ...,  0.2800,  0.8019,  2.3032],\n",
      "        [ 2.3556, -1.3934,  1.5660,  ...,  0.2953,  1.1356,  2.4904]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([356, 64])\n",
      "x.shape  torch.Size([363, 11])\n",
      "edge_index.shape  torch.Size([2, 760])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([760, 11])\n",
      "lin(x_j)  tensor([[ 2.5180, -1.2686,  1.3937,  ..., -0.1303,  1.3984,  2.6979],\n",
      "        [ 1.6752, -0.8587,  1.0233,  ...,  0.2798,  0.8017,  2.3030],\n",
      "        [ 1.6752, -0.8587,  1.0233,  ...,  0.2798,  0.8017,  2.3030],\n",
      "        ...,\n",
      "        [ 0.6300, -0.4255,  0.4992,  ...,  0.2182,  0.3821,  0.3937],\n",
      "        [ 0.6300, -0.4255,  0.4992,  ...,  0.2182,  0.3821,  0.3937],\n",
      "        [ 0.6300, -0.4255,  0.4992,  ...,  0.2182,  0.3821,  0.3937]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([760, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.6752, -0.8587,  1.0233,  ...,  0.2798,  0.8017,  2.3030],\n",
      "        [ 1.5745, -0.8568,  0.9980,  ...,  0.2030,  0.8099,  1.8718],\n",
      "        [ 1.1526, -0.6421,  0.7612,  ...,  0.2490,  0.5919,  1.3484],\n",
      "        ...,\n",
      "        [ 1.4760, -0.8939,  1.1790,  ...,  0.7623,  0.4969,  2.7445],\n",
      "        [ 2.4184, -1.2862,  1.4716,  ...,  0.1109,  1.2460,  2.9187],\n",
      "        [ 1.6752, -0.8587,  1.0233,  ...,  0.2798,  0.8017,  2.3030]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([363, 64])\n",
      "x.shape  torch.Size([373, 11])\n",
      "edge_index.shape  torch.Size([2, 790])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([790, 11])\n",
      "lin(x_j)  tensor([[ 2.4187, -1.2862,  1.4719,  ...,  0.1110,  1.2463,  2.9189],\n",
      "        [ 2.4187, -1.2862,  1.4719,  ...,  0.1110,  1.2463,  2.9189],\n",
      "        [ 1.6752, -0.8587,  1.0233,  ...,  0.2796,  0.8016,  2.3030],\n",
      "        ...,\n",
      "        [ 0.6299, -0.4255,  0.4991,  ...,  0.2181,  0.3820,  0.3936],\n",
      "        [ 0.6299, -0.4255,  0.4991,  ...,  0.2181,  0.3820,  0.3936],\n",
      "        [ 0.6299, -0.4255,  0.4991,  ...,  0.2181,  0.3820,  0.3936]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([790, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.1525, -0.6421,  0.7612,  ...,  0.2489,  0.5918,  1.3483],\n",
      "        [ 1.5997, -0.8573,  1.0044,  ...,  0.2221,  0.8079,  1.9796],\n",
      "        [ 1.3639, -0.7592,  0.9310,  ...,  0.3848,  0.6204,  1.9359],\n",
      "        ...,\n",
      "        [ 1.4754, -0.8939,  1.1784,  ...,  0.7617,  0.4963,  2.7439],\n",
      "        [ 1.4754, -0.8939,  1.1784,  ...,  0.7617,  0.4963,  2.7439],\n",
      "        [ 1.4754, -0.8939,  1.1784,  ...,  0.7617,  0.4963,  2.7439]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([373, 64])\n",
      "x.shape  torch.Size([367, 11])\n",
      "edge_index.shape  torch.Size([2, 754])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 1.,  ..., 0., 0., 2.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 2.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 2.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([754, 11])\n",
      "lin(x_j)  tensor([[ 2.2581, -1.4110,  1.6463,  ...,  0.5388,  0.9855,  2.7133],\n",
      "        [ 2.2581, -1.4110,  1.6463,  ...,  0.5388,  0.9855,  2.7133],\n",
      "        [ 2.2581, -1.4110,  1.6463,  ...,  0.5388,  0.9855,  2.7133],\n",
      "        ...,\n",
      "        [ 0.6300, -0.4255,  0.4992,  ...,  0.2181,  0.3821,  0.3937],\n",
      "        [ 0.6300, -0.4255,  0.4992,  ...,  0.2181,  0.3821,  0.3937],\n",
      "        [ 0.6300, -0.4255,  0.4992,  ...,  0.2181,  0.3821,  0.3937]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([754, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.0118, -0.5640,  0.6482,  ...,  0.1585,  0.5730,  0.9568],\n",
      "        [ 2.1843, -1.1736,  1.3293,  ...,  0.1496,  1.1135,  2.4986],\n",
      "        [ 1.7755, -0.8411,  0.9463,  ...,  0.0391,  0.9549,  2.0831],\n",
      "        ...,\n",
      "        [ 1.5754, -0.8763,  1.1010,  ...,  0.5208,  0.6491,  2.5236],\n",
      "        [ 1.5754, -0.8763,  1.1010,  ...,  0.5208,  0.6491,  2.5236],\n",
      "        [ 2.4194, -1.2862,  1.4727,  ...,  0.1117,  1.2471,  2.9197]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([367, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape  torch.Size([358, 11])\n",
      "edge_index.shape  torch.Size([2, 742])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([742, 11])\n",
      "lin(x_j)  tensor([[ 1.4758, -0.8939,  1.1788,  ...,  0.7621,  0.4967,  2.7443],\n",
      "        [ 1.4758, -0.8939,  1.1788,  ...,  0.7621,  0.4967,  2.7443],\n",
      "        [ 1.4758, -0.8939,  1.1788,  ...,  0.7621,  0.4967,  2.7443],\n",
      "        ...,\n",
      "        [ 0.6302, -0.4255,  0.4994,  ...,  0.2183,  0.3823,  0.3939],\n",
      "        [ 0.6302, -0.4255,  0.4994,  ...,  0.2183,  0.3823,  0.3939],\n",
      "        [ 0.6302, -0.4255,  0.4994,  ...,  0.2183,  0.3823,  0.3939]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([742, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.9168, -0.5294,  0.6114,  ...,  0.1737,  0.5257,  0.8165],\n",
      "        [ 1.7872, -0.9788,  1.1948,  ...,  0.4192,  0.7995,  2.6234],\n",
      "        [ 1.2033, -0.6333,  0.7234,  ...,  0.1292,  0.6691,  1.2390],\n",
      "        ...,\n",
      "        [ 1.4758, -0.8939,  1.1788,  ...,  0.7621,  0.4967,  2.7443],\n",
      "        [ 1.4758, -0.8939,  1.1788,  ...,  0.7621,  0.4967,  2.7443],\n",
      "        [ 2.4206, -1.2862,  1.4741,  ...,  0.1127,  1.2485,  2.9210]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([358, 64])\n",
      "x.shape  torch.Size([362, 11])\n",
      "edge_index.shape  torch.Size([2, 776])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([776, 11])\n",
      "lin(x_j)  tensor([[ 1.4757, -0.8939,  1.1787,  ...,  0.7619,  0.4965,  2.7441],\n",
      "        [ 1.4757, -0.8939,  1.1787,  ...,  0.7619,  0.4965,  2.7441],\n",
      "        [ 1.4757, -0.8939,  1.1787,  ...,  0.7619,  0.4965,  2.7441],\n",
      "        ...,\n",
      "        [ 0.6302, -0.4255,  0.4994,  ...,  0.2183,  0.3824,  0.3940],\n",
      "        [ 0.6302, -0.4255,  0.4994,  ...,  0.2183,  0.3824,  0.3940],\n",
      "        [ 0.6302, -0.4255,  0.4994,  ...,  0.2183,  0.3824,  0.3940]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([776, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8667, -0.5382,  0.6500,  ...,  0.2941,  0.4492,  0.9266],\n",
      "        [ 1.2995, -0.7802,  0.9183,  ...,  0.3148,  0.6391,  1.4522],\n",
      "        [ 1.6096, -0.8704,  1.0762,  ...,  0.4413,  0.7010,  2.4510],\n",
      "        ...,\n",
      "        [ 1.5761, -0.8763,  1.1018,  ...,  0.5214,  0.6499,  2.5243],\n",
      "        [ 2.2609, -1.4110,  1.6494,  ...,  0.5418,  0.9886,  2.7162],\n",
      "        [ 2.2609, -1.4110,  1.6494,  ...,  0.5418,  0.9886,  2.7162]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([362, 64])\n",
      "x.shape  torch.Size([354, 11])\n",
      "edge_index.shape  torch.Size([2, 730])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([730, 11])\n",
      "lin(x_j)  tensor([[ 2.5221, -1.2686,  1.3985,  ..., -0.1274,  1.4030,  2.7024],\n",
      "        [ 1.7770, -0.8411,  0.9481,  ...,  0.0404,  0.9566,  2.0847],\n",
      "        [ 1.7770, -0.8411,  0.9481,  ...,  0.0404,  0.9566,  2.0847],\n",
      "        ...,\n",
      "        [ 0.6301, -0.4255,  0.4993,  ...,  0.2181,  0.3822,  0.3938],\n",
      "        [ 0.6301, -0.4255,  0.4993,  ...,  0.2181,  0.3822,  0.3938],\n",
      "        [ 0.6301, -0.4255,  0.4993,  ...,  0.2181,  0.3822,  0.3938]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([730, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.7770, -0.8411,  0.9481,  ...,  0.0404,  0.9566,  2.0847],\n",
      "        [ 2.2402, -1.1320,  1.2739,  ...,  0.0086,  1.2030,  2.5697],\n",
      "        [ 1.6763, -0.8587,  1.0246,  ...,  0.2806,  0.8030,  2.3042],\n",
      "        ...,\n",
      "        [ 2.4214, -1.2862,  1.4751,  ...,  0.1128,  1.2494,  2.9219],\n",
      "        [ 1.6763, -0.8587,  1.0246,  ...,  0.2806,  0.8030,  2.3042],\n",
      "        [ 1.6763, -0.8587,  1.0246,  ...,  0.2806,  0.8030,  2.3042]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([354, 64])\n",
      "x.shape  torch.Size([365, 11])\n",
      "edge_index.shape  torch.Size([2, 752])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([752, 11])\n",
      "lin(x_j)  tensor([[ 1.4753, -0.8939,  1.1782,  ...,  0.7615,  0.4961,  2.7437],\n",
      "        [ 1.4753, -0.8939,  1.1782,  ...,  0.7615,  0.4961,  2.7437],\n",
      "        [ 1.4753, -0.8939,  1.1782,  ...,  0.7615,  0.4961,  2.7437],\n",
      "        ...,\n",
      "        [ 0.6303, -0.4255,  0.4995,  ...,  0.2182,  0.3824,  0.3940],\n",
      "        [ 0.6303, -0.4255,  0.4995,  ...,  0.2182,  0.3824,  0.3940],\n",
      "        [ 0.6303, -0.4255,  0.4995,  ...,  0.2182,  0.3824,  0.3940]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([752, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8919, -0.5338,  0.6310,  ...,  0.2340,  0.4877,  0.8717],\n",
      "        [ 1.3649, -0.7592,  0.9322,  ...,  0.3856,  0.6215,  1.9369],\n",
      "        [ 1.1789, -0.6377,  0.7434,  ...,  0.1897,  0.6315,  1.2947],\n",
      "        ...,\n",
      "        [ 2.3636, -1.3934,  1.5751,  ...,  0.3036,  1.1444,  2.4988],\n",
      "        [ 1.6770, -0.8587,  1.0255,  ...,  0.2813,  0.8038,  2.3050],\n",
      "        [ 2.3636, -1.3934,  1.5751,  ...,  0.3036,  1.1444,  2.4988]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([365, 64])\n",
      "x.shape  torch.Size([360, 11])\n",
      "edge_index.shape  torch.Size([2, 742])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([742, 11])\n",
      "lin(x_j)  tensor([[ 1.4759, -0.8939,  1.1790,  ...,  0.7622,  0.4968,  2.7444],\n",
      "        [ 1.4759, -0.8939,  1.1790,  ...,  0.7622,  0.4968,  2.7444],\n",
      "        [ 1.4759, -0.8939,  1.1790,  ...,  0.7622,  0.4968,  2.7444],\n",
      "        ...,\n",
      "        [ 0.6305, -0.4255,  0.4998,  ...,  0.2185,  0.3827,  0.3943],\n",
      "        [ 0.6305, -0.4255,  0.4998,  ...,  0.2185,  0.3827,  0.3943],\n",
      "        [ 0.6305, -0.4255,  0.4998,  ...,  0.2185,  0.3827,  0.3943]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([742, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8924, -0.5338,  0.6315,  ...,  0.2344,  0.4882,  0.8722],\n",
      "        [ 1.3909, -0.7548,  0.9139,  ...,  0.3263,  0.6608,  1.8829],\n",
      "        [ 1.4414, -0.7460,  0.8758,  ...,  0.2063,  0.7378,  1.7733],\n",
      "        ...,\n",
      "        [ 1.4759, -0.8939,  1.1790,  ...,  0.7622,  0.4968,  2.7444],\n",
      "        [ 1.4759, -0.8939,  1.1790,  ...,  0.7622,  0.4968,  2.7444],\n",
      "        [ 1.4759, -0.8939,  1.1790,  ...,  0.7622,  0.4968,  2.7444]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([360, 64])\n",
      "x.shape  torch.Size([381, 11])\n",
      "edge_index.shape  torch.Size([2, 794])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([794, 11])\n",
      "lin(x_j)  tensor([[ 1.4765, -0.8939,  1.1797,  ...,  0.7628,  0.4975,  2.7450],\n",
      "        [ 1.4765, -0.8939,  1.1797,  ...,  0.7628,  0.4975,  2.7450],\n",
      "        [ 1.4765, -0.8939,  1.1797,  ...,  0.7628,  0.4975,  2.7450],\n",
      "        ...,\n",
      "        [ 0.6307, -0.4255,  0.5001,  ...,  0.2187,  0.3830,  0.3945],\n",
      "        [ 0.6307, -0.4255,  0.5001,  ...,  0.2187,  0.3830,  0.3945],\n",
      "        [ 0.6307, -0.4255,  0.5001,  ...,  0.2187,  0.3830,  0.3945]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([794, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.9181, -0.5294,  0.6129,  ...,  0.1749,  0.5272,  0.8179],\n",
      "        [ 1.8256, -0.9968,  1.1845,  ...,  0.3492,  0.8529,  2.4106],\n",
      "        [ 1.7294, -0.8499,  0.9896,  ...,  0.1632,  0.8829,  2.1974],\n",
      "        ...,\n",
      "        [ 1.5777, -0.8763,  1.1037,  ...,  0.5230,  0.6517,  2.5260],\n",
      "        [ 1.6788, -0.8587,  1.0276,  ...,  0.2831,  0.8059,  2.3070],\n",
      "        [ 1.6788, -0.8587,  1.0276,  ...,  0.2831,  0.8059,  2.3070]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([381, 64])\n",
      "x.shape  torch.Size([358, 11])\n",
      "edge_index.shape  torch.Size([2, 734])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 2.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([734, 11])\n",
      "lin(x_j)  tensor([[ 2.4264, -1.2862,  1.4810,  ...,  0.1178,  1.2552,  2.9274],\n",
      "        [ 2.4264, -1.2862,  1.4810,  ...,  0.1178,  1.2552,  2.9274],\n",
      "        [ 1.5779, -0.8763,  1.1039,  ...,  0.5232,  0.6519,  2.5262],\n",
      "        ...,\n",
      "        [ 0.6308, -0.4255,  0.5002,  ...,  0.2188,  0.3831,  0.3946],\n",
      "        [ 0.6308, -0.4255,  0.5002,  ...,  0.2188,  0.3831,  0.3946],\n",
      "        [ 0.6308, -0.4255,  0.5002,  ...,  0.2188,  0.3831,  0.3946]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([734, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.1044, -0.6509,  0.8020,  ...,  0.3710,  0.5175,  1.4604],\n",
      "        [ 1.3672, -0.7446,  0.8584,  ...,  0.1498,  0.7455,  1.4513],\n",
      "        [ 1.6455, -0.8646,  1.0534,  ...,  0.3634,  0.7549,  2.3804],\n",
      "        ...,\n",
      "        [ 1.5779, -0.8763,  1.1039,  ...,  0.5232,  0.6519,  2.5262],\n",
      "        [ 1.6793, -0.8587,  1.0281,  ...,  0.2836,  0.8063,  2.3074],\n",
      "        [ 2.4264, -1.2862,  1.4810,  ...,  0.1178,  1.2552,  2.9274]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([358, 64])\n",
      "x.shape  torch.Size([361, 11])\n",
      "edge_index.shape  torch.Size([2, 734])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([734, 11])\n",
      "lin(x_j)  tensor([[ 1.4771, -0.8939,  1.1804,  ...,  0.7635,  0.4982,  2.7457],\n",
      "        [ 1.4771, -0.8939,  1.1804,  ...,  0.7635,  0.4982,  2.7457],\n",
      "        [ 1.4771, -0.8939,  1.1804,  ...,  0.7635,  0.4982,  2.7457],\n",
      "        ...,\n",
      "        [ 0.6311, -0.4255,  0.5004,  ...,  0.2190,  0.3833,  0.3949],\n",
      "        [ 0.6311, -0.4255,  0.5004,  ...,  0.2190,  0.3833,  0.3949],\n",
      "        [ 0.6311, -0.4255,  0.5004,  ...,  0.2190,  0.3833,  0.3949]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([734, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8933, -0.5338,  0.6326,  ...,  0.2354,  0.4893,  0.8732],\n",
      "        [ 1.2910, -0.7724,  0.9915,  ...,  0.5675,  0.5081,  2.1033],\n",
      "        [ 0.8933, -0.5338,  0.6326,  ...,  0.2354,  0.4893,  0.8732],\n",
      "        ...,\n",
      "        [ 1.4771, -0.8939,  1.1804,  ...,  0.7635,  0.4982,  2.7457],\n",
      "        [ 1.4771, -0.8939,  1.1804,  ...,  0.7635,  0.4982,  2.7457],\n",
      "        [ 1.4771, -0.8939,  1.1804,  ...,  0.7635,  0.4982,  2.7457]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([361, 64])\n",
      "x.shape  torch.Size([363, 11])\n",
      "edge_index.shape  torch.Size([2, 764])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([764, 11])\n",
      "lin(x_j)  tensor([[ 1.4770, -0.8939,  1.1802,  ...,  0.7633,  0.4980,  2.7455],\n",
      "        [ 1.4770, -0.8939,  1.1802,  ...,  0.7633,  0.4980,  2.7455],\n",
      "        [ 1.4770, -0.8939,  1.1802,  ...,  0.7633,  0.4980,  2.7455],\n",
      "        ...,\n",
      "        [ 0.6311, -0.4255,  0.5005,  ...,  0.2190,  0.3834,  0.3949],\n",
      "        [ 0.6311, -0.4255,  0.5005,  ...,  0.2190,  0.3834,  0.3949],\n",
      "        [ 0.6311, -0.4255,  0.5005,  ...,  0.2190,  0.3834,  0.3949]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([764, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8680, -0.5382,  0.6515,  ...,  0.2952,  0.4507,  0.9279],\n",
      "        [ 1.1049, -0.6509,  0.8026,  ...,  0.3715,  0.5181,  1.4610],\n",
      "        [ 1.3672, -0.7592,  0.9349,  ...,  0.3879,  0.6241,  1.9394],\n",
      "        ...,\n",
      "        [ 1.5787, -0.8763,  1.1048,  ...,  0.5240,  0.6528,  2.5270],\n",
      "        [ 1.5787, -0.8763,  1.1048,  ...,  0.5240,  0.6528,  2.5270],\n",
      "        [ 2.4284, -1.2862,  1.4833,  ...,  0.1195,  1.2574,  2.9295]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([363, 64])\n",
      "x.shape  torch.Size([381, 11])\n",
      "edge_index.shape  torch.Size([2, 784])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([784, 11])\n",
      "lin(x_j)  tensor([[ 1.4769, -0.8939,  1.1801,  ...,  0.7633,  0.4979,  2.7454],\n",
      "        [ 1.4769, -0.8939,  1.1801,  ...,  0.7633,  0.4979,  2.7454],\n",
      "        [ 1.4769, -0.8939,  1.1801,  ...,  0.7633,  0.4979,  2.7454],\n",
      "        ...,\n",
      "        [ 0.6311, -0.4255,  0.5005,  ...,  0.2190,  0.3834,  0.3949],\n",
      "        [ 0.6311, -0.4255,  0.5005,  ...,  0.2190,  0.3834,  0.3949],\n",
      "        [ 0.6311, -0.4255,  0.5005,  ...,  0.2190,  0.3834,  0.3949]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([784, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.9190, -0.5294,  0.6140,  ...,  0.1757,  0.5283,  0.8188],\n",
      "        [ 1.5533, -0.8807,  1.1237,  ...,  0.5839,  0.6141,  2.5817],\n",
      "        [ 1.3684, -0.7446,  0.8599,  ...,  0.1509,  0.7469,  1.4526],\n",
      "        ...,\n",
      "        [ 1.5787, -0.8763,  1.1049,  ...,  0.5241,  0.6529,  2.5271],\n",
      "        [ 1.5787, -0.8763,  1.1049,  ...,  0.5241,  0.6529,  2.5271],\n",
      "        [ 2.3724, -1.3934,  1.5853,  ...,  0.3129,  1.1543,  2.5082]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([381, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape  torch.Size([342, 11])\n",
      "edge_index.shape  torch.Size([2, 696])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([696, 11])\n",
      "lin(x_j)  tensor([[ 2.4290, -1.2862,  1.4841,  ...,  0.1197,  1.2581,  2.9302],\n",
      "        [ 2.4290, -1.2862,  1.4841,  ...,  0.1197,  1.2581,  2.9302],\n",
      "        [ 1.7826, -0.8411,  0.9546,  ...,  0.0457,  0.9630,  2.0907],\n",
      "        ...,\n",
      "        [ 0.6310, -0.4255,  0.5004,  ...,  0.2188,  0.3833,  0.3948],\n",
      "        [ 0.6310, -0.4255,  0.5004,  ...,  0.2188,  0.3833,  0.3948],\n",
      "        [ 0.6310, -0.4255,  0.5004,  ...,  0.2188,  0.3833,  0.3948]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([696, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.2068, -0.6333,  0.7275,  ...,  0.1323,  0.6731,  1.2428],\n",
      "        [ 1.8421, -0.9700,  1.1619,  ...,  0.3032,  0.8815,  2.5186],\n",
      "        [ 1.1558, -0.6421,  0.7650,  ...,  0.2518,  0.5955,  1.3518],\n",
      "        ...,\n",
      "        [ 1.5784, -0.8763,  1.1045,  ...,  0.5237,  0.6525,  2.5268],\n",
      "        [ 1.5784, -0.8763,  1.1045,  ...,  0.5237,  0.6525,  2.5268],\n",
      "        [ 1.5784, -0.8763,  1.1045,  ...,  0.5237,  0.6525,  2.5268]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([342, 64])\n",
      "x.shape  torch.Size([370, 11])\n",
      "edge_index.shape  torch.Size([2, 764])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([764, 11])\n",
      "lin(x_j)  tensor([[ 1.4767, -0.8939,  1.1799,  ...,  0.7631,  0.4976,  2.7451],\n",
      "        [ 1.4767, -0.8939,  1.1799,  ...,  0.7631,  0.4976,  2.7451],\n",
      "        [ 1.4767, -0.8939,  1.1799,  ...,  0.7631,  0.4976,  2.7451],\n",
      "        ...,\n",
      "        [ 0.6312, -0.4255,  0.5005,  ...,  0.2190,  0.3834,  0.3950],\n",
      "        [ 0.6312, -0.4255,  0.5005,  ...,  0.2190,  0.3834,  0.3950],\n",
      "        [ 0.6312, -0.4255,  0.5005,  ...,  0.2190,  0.3834,  0.3950]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([764, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8681, -0.5382,  0.6517,  ...,  0.2953,  0.4508,  0.9280],\n",
      "        [ 1.0795, -0.6553,  0.8215,  ...,  0.4313,  0.4794,  1.5156],\n",
      "        [ 1.1050, -0.6509,  0.8028,  ...,  0.3716,  0.5182,  1.4611],\n",
      "        ...,\n",
      "        [ 1.5789, -0.8763,  1.1051,  ...,  0.5242,  0.6530,  2.5273],\n",
      "        [ 1.5789, -0.8763,  1.1051,  ...,  0.5242,  0.6530,  2.5273],\n",
      "        [ 1.6811, -0.8587,  1.0303,  ...,  0.2853,  0.8084,  2.3094]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([370, 64])\n",
      "x.shape  torch.Size([368, 11])\n",
      "edge_index.shape  torch.Size([2, 760])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([760, 11])\n",
      "lin(x_j)  tensor([[ 1.4762, -0.8939,  1.1794,  ...,  0.7626,  0.4971,  2.7447],\n",
      "        [ 1.4762, -0.8939,  1.1794,  ...,  0.7626,  0.4971,  2.7447],\n",
      "        [ 1.4762, -0.8939,  1.1794,  ...,  0.7626,  0.4971,  2.7447],\n",
      "        ...,\n",
      "        [ 0.6311, -0.4255,  0.5004,  ...,  0.2189,  0.3833,  0.3949],\n",
      "        [ 0.6311, -0.4255,  0.5004,  ...,  0.2189,  0.3833,  0.3949],\n",
      "        [ 0.6311, -0.4255,  0.5004,  ...,  0.2189,  0.3833,  0.3949]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([760, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8680, -0.5382,  0.6515,  ...,  0.2951,  0.4507,  0.9279],\n",
      "        [ 1.0793, -0.6553,  0.8213,  ...,  0.4311,  0.4791,  1.5154],\n",
      "        [ 1.1305, -0.6465,  0.7840,  ...,  0.3117,  0.5570,  1.4065],\n",
      "        ...,\n",
      "        [ 2.2729, -1.4110,  1.6631,  ...,  0.5545,  1.0018,  2.7289],\n",
      "        [ 2.3753, -1.3934,  1.5885,  ...,  0.3158,  1.1574,  2.5112],\n",
      "        [ 2.4301, -1.2862,  1.4853,  ...,  0.1205,  1.2593,  2.9313]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([368, 64])\n",
      "x.shape  torch.Size([353, 11])\n",
      "edge_index.shape  torch.Size([2, 736])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([736, 11])\n",
      "lin(x_j)  tensor([[ 2.4293, -1.2862,  1.4844,  ...,  0.1194,  1.2585,  2.9305],\n",
      "        [ 2.4293, -1.2862,  1.4844,  ...,  0.1194,  1.2585,  2.9305],\n",
      "        [ 1.7830, -0.8411,  0.9551,  ...,  0.0459,  0.9634,  2.0911],\n",
      "        ...,\n",
      "        [ 0.6308, -0.4255,  0.5001,  ...,  0.2185,  0.3830,  0.3945],\n",
      "        [ 0.6308, -0.4255,  0.5001,  ...,  0.2185,  0.3830,  0.3945],\n",
      "        [ 0.6308, -0.4255,  0.5001,  ...,  0.2185,  0.3830,  0.3945]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([736, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.2069, -0.6333,  0.7276,  ...,  0.1322,  0.6732,  1.2428],\n",
      "        [ 1.8675, -0.9656,  1.1431,  ...,  0.2431,  0.9202,  2.4640],\n",
      "        [ 1.3941, -0.7402,  0.8413,  ...,  0.0910,  0.7860,  1.3983],\n",
      "        ...,\n",
      "        [ 2.4293, -1.2862,  1.4844,  ...,  0.1194,  1.2585,  2.9305],\n",
      "        [ 1.6803, -0.8587,  1.0293,  ...,  0.2844,  0.8075,  2.3085],\n",
      "        [ 2.3753, -1.3934,  1.5885,  ...,  0.3157,  1.1573,  2.5111]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([353, 64])\n",
      "x.shape  torch.Size([376, 11])\n",
      "edge_index.shape  torch.Size([2, 784])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([784, 11])\n",
      "lin(x_j)  tensor([[ 1.4733, -0.8939,  1.1759,  ...,  0.7597,  0.4937,  2.7415],\n",
      "        [ 1.4733, -0.8939,  1.1759,  ...,  0.7597,  0.4937,  2.7415],\n",
      "        [ 1.4733, -0.8939,  1.1759,  ...,  0.7597,  0.4937,  2.7415],\n",
      "        ...,\n",
      "        [ 0.6304, -0.4255,  0.4996,  ...,  0.2180,  0.3825,  0.3941],\n",
      "        [ 0.6304, -0.4255,  0.4996,  ...,  0.2180,  0.3825,  0.3941],\n",
      "        [ 0.6304, -0.4255,  0.4996,  ...,  0.2180,  0.3825,  0.3941]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([784, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8926, -0.5338,  0.6317,  ...,  0.2343,  0.4885,  0.8724],\n",
      "        [ 1.3913, -0.7548,  0.9145,  ...,  0.3265,  0.6613,  1.8834],\n",
      "        [ 1.4171, -0.7504,  0.8960,  ...,  0.2670,  0.7004,  1.8291],\n",
      "        ...,\n",
      "        [ 1.6793, -0.8587,  1.0282,  ...,  0.2833,  0.8063,  2.3074],\n",
      "        [ 1.5763, -0.8763,  1.1020,  ...,  0.5215,  0.6500,  2.5244],\n",
      "        [ 1.5763, -0.8763,  1.1020,  ...,  0.5215,  0.6500,  2.5244]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([376, 64])\n",
      "x.shape  torch.Size([374, 11])\n",
      "edge_index.shape  torch.Size([2, 772])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([772, 11])\n",
      "lin(x_j)  tensor([[ 1.4714, -0.8939,  1.1737,  ...,  0.7577,  0.4915,  2.7394],\n",
      "        [ 1.4714, -0.8939,  1.1737,  ...,  0.7577,  0.4915,  2.7394],\n",
      "        [ 1.4714, -0.8939,  1.1737,  ...,  0.7577,  0.4915,  2.7394],\n",
      "        ...,\n",
      "        [ 0.6299, -0.4255,  0.4990,  ...,  0.2175,  0.3820,  0.3936],\n",
      "        [ 0.6299, -0.4255,  0.4990,  ...,  0.2175,  0.3820,  0.3936],\n",
      "        [ 0.6299, -0.4255,  0.4990,  ...,  0.2175,  0.3820,  0.3936]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([772, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8919, -0.5338,  0.6309,  ...,  0.2336,  0.4877,  0.8717],\n",
      "        [ 1.5384, -0.8929,  1.0717,  ...,  0.3929,  0.7086,  1.9873],\n",
      "        [ 1.1798, -0.6377,  0.7445,  ...,  0.1902,  0.6326,  1.2957],\n",
      "        ...,\n",
      "        [ 1.4714, -0.8939,  1.1737,  ...,  0.7577,  0.4915,  2.7394],\n",
      "        [ 1.4714, -0.8939,  1.1737,  ...,  0.7577,  0.4915,  2.7394],\n",
      "        [ 1.4714, -0.8939,  1.1737,  ...,  0.7577,  0.4915,  2.7394]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([374, 64])\n",
      "x.shape  torch.Size([381, 11])\n",
      "edge_index.shape  torch.Size([2, 798])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([798, 11])\n",
      "lin(x_j)  tensor([[ 2.5298, -1.2686,  1.4075,  ..., -0.1225,  1.4118,  2.7107],\n",
      "        [ 1.6774, -0.8587,  1.0259,  ...,  0.2812,  0.8041,  2.3053],\n",
      "        [ 1.6774, -0.8587,  1.0259,  ...,  0.2812,  0.8041,  2.3053],\n",
      "        ...,\n",
      "        [ 0.6296, -0.4255,  0.4987,  ...,  0.2171,  0.3816,  0.3933],\n",
      "        [ 0.6296, -0.4255,  0.4987,  ...,  0.2171,  0.3816,  0.3933],\n",
      "        [ 0.6296, -0.4255,  0.4987,  ...,  0.2171,  0.3816,  0.3933]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([798, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.6774, -0.8587,  1.0259,  ...,  0.2812,  0.8041,  2.3053],\n",
      "        [ 1.6468, -0.8451,  0.9529,  ...,  0.0460,  0.9182,  1.7310],\n",
      "        [ 1.9034, -0.9836,  1.1296,  ...,  0.1706,  0.9705,  2.2483],\n",
      "        ...,\n",
      "        [ 2.4262, -1.2862,  1.4807,  ...,  0.1152,  1.2548,  2.9271],\n",
      "        [ 1.5738, -0.8763,  1.0991,  ...,  0.5189,  0.6471,  2.5217],\n",
      "        [ 1.5738, -0.8763,  1.0991,  ...,  0.5189,  0.6471,  2.5217]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([381, 64])\n",
      "x.shape  torch.Size([354, 11])\n",
      "edge_index.shape  torch.Size([2, 740])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([740, 11])\n",
      "lin(x_j)  tensor([[ 2.4255, -1.2862,  1.4799,  ...,  0.1142,  1.2540,  2.9264],\n",
      "        [ 2.4255, -1.2862,  1.4799,  ...,  0.1142,  1.2540,  2.9264],\n",
      "        [ 1.7805, -0.8411,  0.9522,  ...,  0.0430,  0.9606,  2.0885],\n",
      "        ...,\n",
      "        [ 0.6293, -0.4255,  0.4984,  ...,  0.2168,  0.3813,  0.3930],\n",
      "        [ 0.6293, -0.4255,  0.4984,  ...,  0.2168,  0.3813,  0.3930],\n",
      "        [ 0.6293, -0.4255,  0.4984,  ...,  0.2168,  0.3813,  0.3930]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([740, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.2049, -0.6333,  0.7253,  ...,  0.1299,  0.6710,  1.2408],\n",
      "        [ 2.1588, -1.1795,  1.3640,  ...,  0.2363,  1.0710,  2.5803],\n",
      "        [ 1.3622, -0.7084,  0.8252,  ...,  0.1801,  0.7151,  1.5954],\n",
      "        ...,\n",
      "        [ 1.5729, -0.8763,  1.0981,  ...,  0.5179,  0.6461,  2.5208],\n",
      "        [ 1.6767, -0.8587,  1.0251,  ...,  0.2805,  0.8033,  2.3046],\n",
      "        [ 1.6767, -0.8587,  1.0251,  ...,  0.2805,  0.8033,  2.3046]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([354, 64])\n",
      "x.shape  torch.Size([379, 11])\n",
      "edge_index.shape  torch.Size([2, 786])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 1.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 1.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([786, 11])\n",
      "lin(x_j)  tensor([[ 2.3736, -1.3934,  1.5863,  ...,  0.3136,  1.1551,  2.5092],\n",
      "        [ 2.3736, -1.3934,  1.5863,  ...,  0.3136,  1.1551,  2.5092],\n",
      "        [ 1.7798, -0.8411,  0.9513,  ...,  0.0421,  0.9597,  2.0877],\n",
      "        ...,\n",
      "        [ 0.6289, -0.4255,  0.4979,  ...,  0.2164,  0.3809,  0.3926],\n",
      "        [ 0.6289, -0.4255,  0.4979,  ...,  0.2164,  0.3809,  0.3926],\n",
      "        [ 0.6289, -0.4255,  0.4979,  ...,  0.2164,  0.3809,  0.3926]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([786, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.2044, -0.6333,  0.7246,  ...,  0.1292,  0.6703,  1.2401],\n",
      "        [ 2.2273, -1.1677,  1.3145,  ...,  0.0770,  1.1750,  2.4354],\n",
      "        [ 1.6757, -0.8587,  1.0239,  ...,  0.2793,  0.8021,  2.3035],\n",
      "        ...,\n",
      "        [ 1.5716, -0.8763,  1.0965,  ...,  0.5166,  0.6445,  2.5194],\n",
      "        [ 1.6757, -0.8587,  1.0239,  ...,  0.2793,  0.8021,  2.3035],\n",
      "        [ 1.6757, -0.8587,  1.0239,  ...,  0.2793,  0.8021,  2.3035]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([379, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape  torch.Size([353, 11])\n",
      "edge_index.shape  torch.Size([2, 748])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([748, 11])\n",
      "lin(x_j)  tensor([[ 1.4655, -0.8939,  1.1667,  ...,  0.7517,  0.4846,  2.7330],\n",
      "        [ 1.4655, -0.8939,  1.1667,  ...,  0.7517,  0.4846,  2.7330],\n",
      "        [ 1.4655, -0.8939,  1.1667,  ...,  0.7517,  0.4846,  2.7330],\n",
      "        ...,\n",
      "        [ 0.6284, -0.4255,  0.4973,  ...,  0.2158,  0.3803,  0.3920],\n",
      "        [ 0.6284, -0.4255,  0.4973,  ...,  0.2158,  0.3803,  0.3920],\n",
      "        [ 0.6284, -0.4255,  0.4973,  ...,  0.2158,  0.3803,  0.3920]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([748, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8638, -0.5382,  0.6466,  ...,  0.2905,  0.4458,  0.9234],\n",
      "        [ 1.3124, -0.7534,  0.8915,  ...,  0.2643,  0.6635,  1.5563],\n",
      "        [ 1.6221, -0.8675,  1.0584,  ...,  0.3963,  0.7215,  2.4098],\n",
      "        ...,\n",
      "        [ 1.5699, -0.8763,  1.0945,  ...,  0.5148,  0.6425,  2.5175],\n",
      "        [ 1.5699, -0.8763,  1.0945,  ...,  0.5148,  0.6425,  2.5175],\n",
      "        [ 2.4229, -1.2862,  1.4768,  ...,  0.1107,  1.2509,  2.9235]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([353, 64])\n",
      "x.shape  torch.Size([354, 11])\n",
      "edge_index.shape  torch.Size([2, 740])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 1.,  ..., 0., 0., 2.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 2.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 2.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([740, 11])\n",
      "lin(x_j)  tensor([[ 2.2679, -1.4110,  1.6570,  ...,  0.5491,  0.9956,  2.7232],\n",
      "        [ 2.2679, -1.4110,  1.6570,  ...,  0.5491,  0.9956,  2.7232],\n",
      "        [ 2.2679, -1.4110,  1.6570,  ...,  0.5491,  0.9956,  2.7232],\n",
      "        ...,\n",
      "        [ 0.6282, -0.4255,  0.4970,  ...,  0.2154,  0.3799,  0.3917],\n",
      "        [ 0.6282, -0.4255,  0.4970,  ...,  0.2154,  0.3799,  0.3917],\n",
      "        [ 0.6282, -0.4255,  0.4970,  ...,  0.2154,  0.3799,  0.3917]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([740, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.0116, -0.5640,  0.6478,  ...,  0.1571,  0.5726,  0.9565],\n",
      "        [ 2.1745, -1.2093,  1.3732,  ...,  0.2217,  1.0886,  2.3674],\n",
      "        [ 2.0755, -1.1173,  1.2673,  ...,  0.1764,  1.0560,  2.2971],\n",
      "        ...,\n",
      "        [ 1.5690, -0.8763,  1.0934,  ...,  0.5138,  0.6414,  2.5165],\n",
      "        [ 1.5690, -0.8763,  1.0934,  ...,  0.5138,  0.6414,  2.5165],\n",
      "        [ 1.6737, -0.8587,  1.0215,  ...,  0.2771,  0.7997,  2.3013]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([354, 64])\n",
      "x.shape  torch.Size([352, 11])\n",
      "edge_index.shape  torch.Size([2, 728])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([728, 11])\n",
      "lin(x_j)  tensor([[ 1.4625, -0.8939,  1.1632,  ...,  0.7487,  0.4811,  2.7297],\n",
      "        [ 1.4625, -0.8939,  1.1632,  ...,  0.7487,  0.4811,  2.7297],\n",
      "        [ 1.4625, -0.8939,  1.1632,  ...,  0.7487,  0.4811,  2.7297],\n",
      "        ...,\n",
      "        [ 0.6277, -0.4255,  0.4964,  ...,  0.2149,  0.3794,  0.3912],\n",
      "        [ 0.6277, -0.4255,  0.4964,  ...,  0.2149,  0.3794,  0.3912],\n",
      "        [ 0.6277, -0.4255,  0.4964,  ...,  0.2149,  0.3794,  0.3912]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([728, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8627, -0.5382,  0.6453,  ...,  0.2893,  0.4445,  0.9221],\n",
      "        [ 1.1239, -0.6465,  0.7762,  ...,  0.3045,  0.5493,  1.3994],\n",
      "        [ 1.8334, -0.9700,  1.1516,  ...,  0.2930,  0.8713,  2.5091],\n",
      "        ...,\n",
      "        [ 1.5675, -0.8763,  1.0917,  ...,  0.5123,  0.6397,  2.5149],\n",
      "        [ 1.6725, -0.8587,  1.0201,  ...,  0.2758,  0.7984,  2.3001],\n",
      "        [ 1.6725, -0.8587,  1.0201,  ...,  0.2758,  0.7984,  2.3001]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([352, 64])\n",
      "x.shape  torch.Size([345, 11])\n",
      "edge_index.shape  torch.Size([2, 726])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([726, 11])\n",
      "lin(x_j)  tensor([[ 1.4606, -0.8939,  1.1611,  ...,  0.7469,  0.4789,  2.7277],\n",
      "        [ 1.4606, -0.8939,  1.1611,  ...,  0.7469,  0.4789,  2.7277],\n",
      "        [ 1.4606, -0.8939,  1.1611,  ...,  0.7469,  0.4789,  2.7277],\n",
      "        ...,\n",
      "        [ 0.6273, -0.4255,  0.4959,  ...,  0.2144,  0.3789,  0.3908],\n",
      "        [ 0.6273, -0.4255,  0.4959,  ...,  0.2144,  0.3789,  0.3908],\n",
      "        [ 0.6273, -0.4255,  0.4959,  ...,  0.2144,  0.3789,  0.3908]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([726, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8883, -0.5338,  0.6266,  ...,  0.2295,  0.4835,  0.8678],\n",
      "        [ 1.5711, -0.8617,  1.0194,  ...,  0.2766,  0.7653,  2.0307],\n",
      "        [ 1.6714, -0.8587,  1.0188,  ...,  0.2746,  0.7971,  2.2988],\n",
      "        ...,\n",
      "        [ 1.5660, -0.8763,  1.0899,  ...,  0.5108,  0.6380,  2.5133],\n",
      "        [ 1.6714, -0.8587,  1.0188,  ...,  0.2746,  0.7971,  2.2988],\n",
      "        [ 1.6714, -0.8587,  1.0188,  ...,  0.2746,  0.7971,  2.2988]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([345, 64])\n",
      "x.shape  torch.Size([379, 11])\n",
      "edge_index.shape  torch.Size([2, 782])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([782, 11])\n",
      "lin(x_j)  tensor([[ 2.4182, -1.2862,  1.4713,  ...,  0.1047,  1.2454,  2.9184],\n",
      "        [ 2.4182, -1.2862,  1.4713,  ...,  0.1047,  1.2454,  2.9184],\n",
      "        [ 1.6700, -0.8587,  1.0172,  ...,  0.2732,  0.7955,  2.2974],\n",
      "        ...,\n",
      "        [ 0.6268, -0.4255,  0.4953,  ...,  0.2139,  0.3783,  0.3902],\n",
      "        [ 0.6268, -0.4255,  0.4953,  ...,  0.2139,  0.3783,  0.3902],\n",
      "        [ 0.6268, -0.4255,  0.4953,  ...,  0.2139,  0.3783,  0.3902]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([782, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.1484, -0.6421,  0.7563,  ...,  0.2435,  0.5869,  1.3438],\n",
      "        [ 1.5963, -0.8573,  1.0002,  ...,  0.2162,  0.8037,  1.9758],\n",
      "        [ 1.6372, -0.8753,  0.9927,  ...,  0.1497,  0.8600,  1.7657],\n",
      "        ...,\n",
      "        [ 1.5643, -0.8763,  1.0879,  ...,  0.5090,  0.6360,  2.5114],\n",
      "        [ 1.6700, -0.8587,  1.0172,  ...,  0.2732,  0.7955,  2.2974],\n",
      "        [ 1.6700, -0.8587,  1.0172,  ...,  0.2732,  0.7955,  2.2974]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([379, 64])\n",
      "x.shape  torch.Size([339, 11])\n",
      "edge_index.shape  torch.Size([2, 698])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([698, 11])\n",
      "lin(x_j)  tensor([[ 2.4167, -1.2862,  1.4694,  ...,  0.1027,  1.2436,  2.9168],\n",
      "        [ 2.4167, -1.2862,  1.4694,  ...,  0.1027,  1.2436,  2.9168],\n",
      "        [ 1.6686, -0.8587,  1.0155,  ...,  0.2716,  0.7938,  2.2958],\n",
      "        ...,\n",
      "        [ 0.6262, -0.4255,  0.4947,  ...,  0.2133,  0.3777,  0.3896],\n",
      "        [ 0.6262, -0.4255,  0.4947,  ...,  0.2133,  0.3777,  0.3896],\n",
      "        [ 0.6262, -0.4255,  0.4947,  ...,  0.2133,  0.3777,  0.3896]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([698, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.1474, -0.6421,  0.7551,  ...,  0.2425,  0.5858,  1.3427],\n",
      "        [ 1.5950, -0.8573,  0.9988,  ...,  0.2148,  0.8022,  1.9745],\n",
      "        [ 1.3610, -0.7446,  0.8510,  ...,  0.1413,  0.7382,  1.4445],\n",
      "        ...,\n",
      "        [ 1.6686, -0.8587,  1.0155,  ...,  0.2716,  0.7938,  2.2958],\n",
      "        [ 1.5625, -0.8763,  1.0858,  ...,  0.5072,  0.6339,  2.5095],\n",
      "        [ 1.5625, -0.8763,  1.0858,  ...,  0.5072,  0.6339,  2.5095]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([339, 64])\n",
      "x.shape  torch.Size([381, 11])\n",
      "edge_index.shape  torch.Size([2, 776])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([776, 11])\n",
      "lin(x_j)  tensor([[ 1.4555, -0.8939,  1.1551,  ...,  0.7419,  0.4730,  2.7222],\n",
      "        [ 1.4555, -0.8939,  1.1551,  ...,  0.7419,  0.4730,  2.7222],\n",
      "        [ 1.4555, -0.8939,  1.1551,  ...,  0.7419,  0.4730,  2.7222],\n",
      "        ...,\n",
      "        [ 0.6261, -0.4255,  0.4945,  ...,  0.2131,  0.3775,  0.3895],\n",
      "        [ 0.6261, -0.4255,  0.4945,  ...,  0.2131,  0.3775,  0.3895],\n",
      "        [ 0.6261, -0.4255,  0.4945,  ...,  0.2131,  0.3775,  0.3895]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([776, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8866, -0.5338,  0.6247,  ...,  0.2276,  0.4815,  0.8660],\n",
      "        [ 1.3545, -0.7592,  0.9200,  ...,  0.3743,  0.6093,  1.9257],\n",
      "        [ 1.1206, -0.6465,  0.7723,  ...,  0.3010,  0.5454,  1.3958],\n",
      "        ...,\n",
      "        [ 1.4555, -0.8939,  1.1551,  ...,  0.7419,  0.4730,  2.7222],\n",
      "        [ 1.4555, -0.8939,  1.1551,  ...,  0.7419,  0.4730,  2.7222],\n",
      "        [ 1.4555, -0.8939,  1.1551,  ...,  0.7419,  0.4730,  2.7222]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([381, 64])\n",
      "x.shape  torch.Size([378, 11])\n",
      "edge_index.shape  torch.Size([2, 772])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([772, 11])\n",
      "lin(x_j)  tensor([[ 1.4543, -0.8939,  1.1537,  ...,  0.7406,  0.4716,  2.7209],\n",
      "        [ 1.4543, -0.8939,  1.1537,  ...,  0.7406,  0.4716,  2.7209],\n",
      "        [ 1.4543, -0.8939,  1.1537,  ...,  0.7406,  0.4716,  2.7209],\n",
      "        ...,\n",
      "        [ 0.6258, -0.4255,  0.4942,  ...,  0.2127,  0.3772,  0.3891],\n",
      "        [ 0.6258, -0.4255,  0.4942,  ...,  0.2127,  0.3772,  0.3891],\n",
      "        [ 0.6258, -0.4255,  0.4942,  ...,  0.2127,  0.3772,  0.3891]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([772, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.9129, -0.5294,  0.6068,  ...,  0.1684,  0.5212,  0.8123],\n",
      "        [ 1.5876, -0.8719,  1.0666,  ...,  0.4468,  0.6723,  2.4546],\n",
      "        [ 1.3604, -0.7446,  0.8503,  ...,  0.1405,  0.7375,  1.4439],\n",
      "        ...,\n",
      "        [ 1.6676, -0.8587,  1.0143,  ...,  0.2704,  0.7927,  2.2948],\n",
      "        [ 2.3700, -1.3934,  1.5818,  ...,  0.3092,  1.1506,  2.5051],\n",
      "        [ 1.6676, -0.8587,  1.0143,  ...,  0.2704,  0.7927,  2.2948]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([378, 64])\n",
      "x.shape  torch.Size([353, 11])\n",
      "edge_index.shape  torch.Size([2, 742])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([742, 11])\n",
      "lin(x_j)  tensor([[ 1.4522, -0.8939,  1.1512,  ...,  0.7385,  0.4691,  2.7186],\n",
      "        [ 1.4522, -0.8939,  1.1512,  ...,  0.7385,  0.4691,  2.7186],\n",
      "        [ 1.4522, -0.8939,  1.1512,  ...,  0.7385,  0.4691,  2.7186],\n",
      "        ...,\n",
      "        [ 0.6252, -0.4255,  0.4935,  ...,  0.2121,  0.3766,  0.3886],\n",
      "        [ 0.6252, -0.4255,  0.4935,  ...,  0.2121,  0.3766,  0.3886],\n",
      "        [ 0.6252, -0.4255,  0.4935,  ...,  0.2121,  0.3766,  0.3886]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([742, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8587, -0.5382,  0.6406,  ...,  0.2850,  0.4399,  0.9179],\n",
      "        [ 1.0655, -0.6553,  0.8051,  ...,  0.4166,  0.4631,  1.5004],\n",
      "        [ 1.1457, -0.6421,  0.7531,  ...,  0.2405,  0.5838,  1.3409],\n",
      "        ...,\n",
      "        [ 2.2620, -1.4110,  1.6499,  ...,  0.5429,  0.9885,  2.7167],\n",
      "        [ 2.3690, -1.3934,  1.5806,  ...,  0.3081,  1.1495,  2.5041],\n",
      "        [ 1.6662, -0.8587,  1.0127,  ...,  0.2689,  0.7910,  2.2932]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([353, 64])\n",
      "x.shape  torch.Size([360, 11])\n",
      "edge_index.shape  torch.Size([2, 732])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 1.,  ..., 0., 0., 2.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 2.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 2.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([732, 11])\n",
      "lin(x_j)  tensor([[ 2.2606, -1.4110,  1.6483,  ...,  0.5415,  0.9869,  2.7153],\n",
      "        [ 2.2606, -1.4110,  1.6483,  ...,  0.5415,  0.9869,  2.7153],\n",
      "        [ 2.2606, -1.4110,  1.6483,  ...,  0.5415,  0.9869,  2.7153],\n",
      "        ...,\n",
      "        [ 0.6247, -0.4255,  0.4928,  ...,  0.2115,  0.3759,  0.3879],\n",
      "        [ 0.6247, -0.4255,  0.4928,  ...,  0.2115,  0.3759,  0.3879],\n",
      "        [ 0.6247, -0.4255,  0.4928,  ...,  0.2115,  0.3759,  0.3879]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([732, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.0071, -0.5640,  0.6426,  ...,  0.1520,  0.5675,  0.9517],\n",
      "        [ 2.4187, -1.3518,  1.5182,  ...,  0.1589,  1.2323,  2.5687],\n",
      "        [ 1.7721, -0.8411,  0.9421,  ...,  0.0329,  0.9507,  2.0793],\n",
      "        ...,\n",
      "        [ 2.3680, -1.3934,  1.5795,  ...,  0.3071,  1.1483,  2.5030],\n",
      "        [ 1.6647, -0.8587,  1.0109,  ...,  0.2674,  0.7893,  2.2916],\n",
      "        [ 1.6647, -0.8587,  1.0109,  ...,  0.2674,  0.7893,  2.2916]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([360, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape  torch.Size([368, 11])\n",
      "edge_index.shape  torch.Size([2, 746])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([746, 11])\n",
      "lin(x_j)  tensor([[ 2.4113, -1.2862,  1.4632,  ...,  0.0958,  1.2375,  2.9110],\n",
      "        [ 2.4113, -1.2862,  1.4632,  ...,  0.0958,  1.2375,  2.9110],\n",
      "        [ 2.4752, -1.3759,  1.5103,  ...,  0.0722,  1.3094,  2.2904],\n",
      "        ...,\n",
      "        [ 0.6242, -0.4255,  0.4923,  ...,  0.2110,  0.3754,  0.3875],\n",
      "        [ 0.6242, -0.4255,  0.4923,  ...,  0.2110,  0.3754,  0.3875],\n",
      "        [ 0.6242, -0.4255,  0.4923,  ...,  0.2110,  0.3754,  0.3875]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([746, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.5497, -0.9007,  1.0013,  ...,  0.1416,  0.8424,  1.3389],\n",
      "        [ 2.0913, -1.0637,  1.2022,  ...,  0.0638,  1.0936,  2.4948],\n",
      "        [ 1.9341, -1.0311,  1.1765,  ...,  0.2015,  0.9617,  2.2904],\n",
      "        ...,\n",
      "        [ 1.4481, -0.8939,  1.1465,  ...,  0.7346,  0.4643,  2.7142],\n",
      "        [ 1.6635, -0.8587,  1.0096,  ...,  0.2661,  0.7879,  2.2904],\n",
      "        [ 1.6635, -0.8587,  1.0096,  ...,  0.2661,  0.7879,  2.2904]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([368, 64])\n",
      "x.shape  torch.Size([362, 11])\n",
      "edge_index.shape  torch.Size([2, 740])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([740, 11])\n",
      "lin(x_j)  tensor([[ 1.4473, -0.8939,  1.1456,  ...,  0.7337,  0.4634,  2.7134],\n",
      "        [ 1.4473, -0.8939,  1.1456,  ...,  0.7337,  0.4634,  2.7134],\n",
      "        [ 1.4473, -0.8939,  1.1456,  ...,  0.7337,  0.4634,  2.7134],\n",
      "        ...,\n",
      "        [ 0.6240, -0.4255,  0.4921,  ...,  0.2108,  0.3752,  0.3873],\n",
      "        [ 0.6240, -0.4255,  0.4921,  ...,  0.2108,  0.3752,  0.3873],\n",
      "        [ 0.6240, -0.4255,  0.4921,  ...,  0.2108,  0.3752,  0.3873]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([740, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.9108, -0.5294,  0.6043,  ...,  0.1660,  0.5188,  0.8101],\n",
      "        [ 1.5912, -0.8704,  1.0547,  ...,  0.4217,  0.6795,  2.4312],\n",
      "        [ 1.3168, -0.7143,  0.8369,  ...,  0.2474,  0.6501,  1.6558],\n",
      "        ...,\n",
      "        [ 2.2598, -1.4110,  1.6473,  ...,  0.5405,  0.9859,  2.7143],\n",
      "        [ 1.6632, -0.8587,  1.0092,  ...,  0.2657,  0.7876,  2.2900],\n",
      "        [ 2.4112, -1.2862,  1.4630,  ...,  0.0952,  1.2373,  2.9109]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([362, 64])\n",
      "x.shape  torch.Size([370, 11])\n",
      "edge_index.shape  torch.Size([2, 768])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([768, 11])\n",
      "lin(x_j)  tensor([[ 1.4468, -0.8939,  1.1449,  ...,  0.7331,  0.4628,  2.7128],\n",
      "        [ 1.4468, -0.8939,  1.1449,  ...,  0.7331,  0.4628,  2.7128],\n",
      "        [ 1.4468, -0.8939,  1.1449,  ...,  0.7331,  0.4628,  2.7128],\n",
      "        ...,\n",
      "        [ 0.6239, -0.4255,  0.4920,  ...,  0.2106,  0.3751,  0.3872],\n",
      "        [ 0.6239, -0.4255,  0.4920,  ...,  0.2106,  0.3751,  0.3872],\n",
      "        [ 0.6239, -0.4255,  0.4920,  ...,  0.2106,  0.3751,  0.3872]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([768, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8567, -0.5382,  0.6382,  ...,  0.2828,  0.4376,  0.9157],\n",
      "        [ 1.0624, -0.6553,  0.8015,  ...,  0.4134,  0.4595,  1.4971],\n",
      "        [ 1.3306, -0.7490,  0.8641,  ...,  0.1954,  0.6937,  1.4938],\n",
      "        ...,\n",
      "        [ 1.5549, -0.8763,  1.0770,  ...,  0.4993,  0.6251,  2.5014],\n",
      "        [ 1.5549, -0.8763,  1.0770,  ...,  0.4993,  0.6251,  2.5014],\n",
      "        [ 1.5549, -0.8763,  1.0770,  ...,  0.4993,  0.6251,  2.5014]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([370, 64])\n",
      "x.shape  torch.Size([383, 11])\n",
      "edge_index.shape  torch.Size([2, 784])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([784, 11])\n",
      "lin(x_j)  tensor([[ 2.4772, -1.3759,  1.5125,  ...,  0.0735,  1.3116,  2.2924],\n",
      "        [ 1.7712, -0.8411,  0.9411,  ...,  0.0314,  0.9497,  2.0784],\n",
      "        [ 1.7712, -0.8411,  0.9411,  ...,  0.0314,  0.9497,  2.0784],\n",
      "        ...,\n",
      "        [ 0.6237, -0.4255,  0.4918,  ...,  0.2104,  0.3748,  0.3870],\n",
      "        [ 0.6237, -0.4255,  0.4918,  ...,  0.2104,  0.3748,  0.3870],\n",
      "        [ 0.6237, -0.4255,  0.4918,  ...,  0.2104,  0.3748,  0.3870]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([784, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.7712, -0.8411,  0.9411,  ...,  0.0314,  0.9497,  2.0784],\n",
      "        [ 2.0158, -1.1261,  1.2944,  ...,  0.2861,  0.9680,  2.3966],\n",
      "        [ 1.3469, -0.7714,  0.8762,  ...,  0.1898,  0.7121,  1.3390],\n",
      "        ...,\n",
      "        [ 2.3687, -1.3934,  1.5801,  ...,  0.3071,  1.1490,  2.5036],\n",
      "        [ 1.6628, -0.8587,  1.0087,  ...,  0.2650,  0.7871,  2.2896],\n",
      "        [ 1.6628, -0.8587,  1.0087,  ...,  0.2650,  0.7871,  2.2896]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([383, 64])\n",
      "x.shape  torch.Size([365, 11])\n",
      "edge_index.shape  torch.Size([2, 744])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([744, 11])\n",
      "lin(x_j)  tensor([[ 1.4450, -0.8939,  1.1429,  ...,  0.7314,  0.4607,  2.7109],\n",
      "        [ 1.4450, -0.8939,  1.1429,  ...,  0.7314,  0.4607,  2.7109],\n",
      "        [ 1.4450, -0.8939,  1.1429,  ...,  0.7314,  0.4607,  2.7109],\n",
      "        ...,\n",
      "        [ 0.6235, -0.4255,  0.4915,  ...,  0.2101,  0.3746,  0.3867],\n",
      "        [ 0.6235, -0.4255,  0.4915,  ...,  0.2101,  0.3746,  0.3867],\n",
      "        [ 0.6235, -0.4255,  0.4915,  ...,  0.2101,  0.3746,  0.3867]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([744, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.0599, -0.6675,  0.7637,  ...,  0.2344,  0.5682,  0.9160],\n",
      "        [ 1.2799, -0.7202,  0.8584,  ...,  0.3242,  0.5949,  1.7253],\n",
      "        [ 1.8662, -0.9880,  1.1344,  ...,  0.2169,  0.9179,  2.2900],\n",
      "        ...,\n",
      "        [ 2.3689, -1.3934,  1.5803,  ...,  0.3072,  1.1492,  2.5038],\n",
      "        [ 2.3689, -1.3934,  1.5803,  ...,  0.3072,  1.1492,  2.5038],\n",
      "        [ 1.6624, -0.8587,  1.0082,  ...,  0.2646,  0.7866,  2.2891]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([365, 64])\n",
      "x.shape  torch.Size([371, 11])\n",
      "edge_index.shape  torch.Size([2, 756])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([756, 11])\n",
      "lin(x_j)  tensor([[ 2.5203, -1.2686,  1.3961,  ..., -0.1389,  1.4006,  2.7003],\n",
      "        [ 1.7717, -0.8411,  0.9417,  ...,  0.0317,  0.9503,  2.0789],\n",
      "        [ 1.7717, -0.8411,  0.9417,  ...,  0.0317,  0.9503,  2.0789],\n",
      "        ...,\n",
      "        [ 0.6237, -0.4255,  0.4917,  ...,  0.2102,  0.3747,  0.3869],\n",
      "        [ 0.6237, -0.4255,  0.4917,  ...,  0.2102,  0.3747,  0.3869],\n",
      "        [ 0.6237, -0.4255,  0.4917,  ...,  0.2102,  0.3747,  0.3869]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([756, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 1.7717, -0.8411,  0.9417,  ...,  0.0317,  0.9503,  2.0789],\n",
      "        [ 1.8761, -1.0071,  1.1827,  ...,  0.2859,  0.8830,  2.5670],\n",
      "        [ 1.1977, -0.6333,  0.7167,  ...,  0.1209,  0.6625,  1.2329],\n",
      "        ...,\n",
      "        [ 1.5541, -0.8763,  1.0760,  ...,  0.4983,  0.6241,  2.5004],\n",
      "        [ 1.5541, -0.8763,  1.0760,  ...,  0.4983,  0.6241,  2.5004],\n",
      "        [ 2.3702, -1.3934,  1.5817,  ...,  0.3083,  1.1506,  2.5051]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([371, 64])\n",
      "x.shape  torch.Size([374, 11])\n",
      "edge_index.shape  torch.Size([2, 776])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([776, 11])\n",
      "lin(x_j)  tensor([[ 1.4462, -0.8939,  1.1443,  ...,  0.7324,  0.4622,  2.7121],\n",
      "        [ 1.4462, -0.8939,  1.1443,  ...,  0.7324,  0.4622,  2.7121],\n",
      "        [ 1.4462, -0.8939,  1.1443,  ...,  0.7324,  0.4622,  2.7121],\n",
      "        ...,\n",
      "        [ 0.6240, -0.4255,  0.4920,  ...,  0.2105,  0.3751,  0.3872],\n",
      "        [ 0.6240, -0.4255,  0.4920,  ...,  0.2105,  0.3751,  0.3872],\n",
      "        [ 0.6240, -0.4255,  0.4920,  ...,  0.2105,  0.3751,  0.3872]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([776, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.9112, -0.5294,  0.6048,  ...,  0.1660,  0.5193,  0.8104],\n",
      "        [ 1.7968, -0.9744,  1.1574,  ...,  0.3400,  0.8196,  2.5516],\n",
      "        [ 1.1984, -0.6333,  0.7175,  ...,  0.1216,  0.6634,  1.2337],\n",
      "        ...,\n",
      "        [ 1.5551, -0.8763,  1.0772,  ...,  0.4992,  0.6254,  2.5015],\n",
      "        [ 1.5551, -0.8763,  1.0772,  ...,  0.4992,  0.6254,  2.5015],\n",
      "        [ 1.6640, -0.8587,  1.0101,  ...,  0.2660,  0.7885,  2.2908]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([374, 64])\n",
      "x.shape  torch.Size([359, 11])\n",
      "edge_index.shape  torch.Size([2, 748])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([748, 11])\n",
      "lin(x_j)  tensor([[ 1.4473, -0.8939,  1.1456,  ...,  0.7333,  0.4634,  2.7132],\n",
      "        [ 1.4473, -0.8939,  1.1456,  ...,  0.7333,  0.4634,  2.7132],\n",
      "        [ 1.4473, -0.8939,  1.1456,  ...,  0.7333,  0.4634,  2.7132],\n",
      "        ...,\n",
      "        [ 0.6243, -0.4255,  0.4924,  ...,  0.2108,  0.3755,  0.3876],\n",
      "        [ 0.6243, -0.4255,  0.4924,  ...,  0.2108,  0.3755,  0.3876],\n",
      "        [ 0.6243, -0.4255,  0.4924,  ...,  0.2108,  0.3755,  0.3876]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([748, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.9118, -0.5294,  0.6055,  ...,  0.1665,  0.5199,  0.8110],\n",
      "        [ 1.7607, -1.0056,  1.2055,  ...,  0.4531,  0.7588,  2.5043],\n",
      "        [ 1.1720, -0.6377,  0.7352,  ...,  0.1806,  0.6235,  1.2872],\n",
      "        ...,\n",
      "        [ 1.6652, -0.8587,  1.0115,  ...,  0.2670,  0.7899,  2.2921],\n",
      "        [ 2.2651, -1.4110,  1.6532,  ...,  0.5450,  0.9918,  2.7197],\n",
      "        [ 2.2651, -1.4110,  1.6532,  ...,  0.5450,  0.9918,  2.7197]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([359, 64])\n",
      "x.shape  torch.Size([362, 11])\n",
      "edge_index.shape  torch.Size([2, 750])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([750, 11])\n",
      "lin(x_j)  tensor([[ 1.4489, -0.8939,  1.1474,  ...,  0.7348,  0.4653,  2.7149],\n",
      "        [ 1.4489, -0.8939,  1.1474,  ...,  0.7348,  0.4653,  2.7149],\n",
      "        [ 1.4489, -0.8939,  1.1474,  ...,  0.7348,  0.4653,  2.7149],\n",
      "        ...,\n",
      "        [ 0.6248, -0.4255,  0.4930,  ...,  0.2112,  0.3761,  0.3881],\n",
      "        [ 0.6248, -0.4255,  0.4930,  ...,  0.2112,  0.3761,  0.3881],\n",
      "        [ 0.6248, -0.4255,  0.4930,  ...,  0.2112,  0.3761,  0.3881]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin(x_j).shape  torch.Size([750, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.8853, -0.5338,  0.6231,  ...,  0.2255,  0.4800,  0.8645],\n",
      "        [ 1.5293, -0.8929,  1.0607,  ...,  0.3821,  0.6978,  1.9771],\n",
      "        [ 1.3195, -0.7143,  0.8400,  ...,  0.2494,  0.6533,  1.6586],\n",
      "        ...,\n",
      "        [ 2.2676, -1.4110,  1.6560,  ...,  0.5472,  0.9947,  2.7223],\n",
      "        [ 2.4168, -1.2862,  1.4695,  ...,  0.0988,  1.2438,  2.9167],\n",
      "        [ 1.6669, -0.8587,  1.0135,  ...,  0.2685,  0.7919,  2.2938]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([362, 64])\n",
      "x.shape  torch.Size([352, 11])\n",
      "edge_index.shape  torch.Size([2, 732])\n",
      "forward\n",
      "message\n",
      "x_j  tensor([[0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 3.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "x_j.shape  torch.Size([732, 11])\n",
      "lin(x_j)  tensor([[ 1.4500, -0.8939,  1.1487,  ...,  0.7358,  0.4666,  2.7161],\n",
      "        [ 1.4500, -0.8939,  1.1487,  ...,  0.7358,  0.4666,  2.7161],\n",
      "        [ 1.4500, -0.8939,  1.1487,  ...,  0.7358,  0.4666,  2.7161],\n",
      "        ...,\n",
      "        [ 0.6252, -0.4255,  0.4935,  ...,  0.2115,  0.3765,  0.3885],\n",
      "        [ 0.6252, -0.4255,  0.4935,  ...,  0.2115,  0.3765,  0.3885],\n",
      "        [ 0.6252, -0.4255,  0.4935,  ...,  0.2115,  0.3765,  0.3885]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "lin(x_j).shape  torch.Size([732, 64])\n",
      "update\n",
      "aggr_out  tensor([[ 0.9132, -0.5294,  0.6071,  ...,  0.1678,  0.5216,  0.8125],\n",
      "        [ 2.0161, -1.0769,  1.2600,  ...,  0.2432,  0.9788,  2.6595],\n",
      "        [ 1.1467, -0.6421,  0.7542,  ...,  0.2406,  0.5850,  1.3418],\n",
      "        ...,\n",
      "        [ 1.6682, -0.8587,  1.0150,  ...,  0.2696,  0.7934,  2.2952],\n",
      "        [ 1.6682, -0.8587,  1.0150,  ...,  0.2696,  0.7934,  2.2952],\n",
      "        [ 2.3788, -1.3934,  1.5915,  ...,  0.3161,  1.1604,  2.5140]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "aggr_out.shape  torch.Size([352, 64])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m     12\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[0;32m     14\u001b[0m         batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch_geometric\\data\\dataset.py:258\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"In case :obj:`idx` is of type integer, will return the data object\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03mat index :obj:`idx` (and transforms it in case :obj:`transform` is\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03mpresent).\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03mIn case :obj:`idx` is a slicing object, *e.g.*, :obj:`[2:5]`, a list, a\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03mtuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type long or\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124;03mbool, will return a subset of the dataset at the specified indices.\"\"\"\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[1;32m--> 258\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:84\u001b[0m, in \u001b[0;36mInMemoryDataset.get\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_list[idx] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_list[idx])\n\u001b[1;32m---> 84\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mseparate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_list[idx] \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(data)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch_geometric\\data\\separate.py:37\u001b[0m, in \u001b[0;36mseparate\u001b[1;34m(cls, batch, idx, slice_dict, inc_dict, decrement)\u001b[0m\n\u001b[0;32m     35\u001b[0m         slices \u001b[38;5;241m=\u001b[39m slice_dict[attr]\n\u001b[0;32m     36\u001b[0m         incs \u001b[38;5;241m=\u001b[39m inc_dict[attr] \u001b[38;5;28;01mif\u001b[39;00m decrement \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     data_store[attr] \u001b[38;5;241m=\u001b[39m \u001b[43m_separate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_store\u001b[49m\u001b[43m[\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mincs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecrement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# The `num_nodes` attribute needs special treatment, as we cannot infer\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# the real number of nodes from the total number of nodes alone:\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(batch_store, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_num_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch_geometric\\data\\separate.py:65\u001b[0m, in \u001b[0;36m_separate\u001b[1;34m(key, value, idx, slices, incs, batch, store, decrement)\u001b[0m\n\u001b[0;32m     63\u001b[0m cat_dim \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39m__cat_dim__(key, value, store)\n\u001b[0;32m     64\u001b[0m start, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(slices[idx]), \u001b[38;5;28mint\u001b[39m(slices[idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 65\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnarrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m cat_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decrement \u001b[38;5;129;01mand\u001b[39;00m (incs\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mint\u001b[39m(incs[idx]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "# Training loop\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "min_valid_loss = np.inf\n",
    "loss_values = []\n",
    "val_loss_values = []\n",
    "\n",
    "for epoch in range(config[\"num_epochs\"]):\n",
    "    total_loss = 0\n",
    "    for batch in val_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch).flatten()\n",
    "        loss = config[\"criterion\"](output, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "\n",
    "    average_loss = total_loss  / len(val_loader.dataset)\n",
    "    loss_values.append(average_loss)\n",
    "    print(f'Epoch: {epoch}, Training Loss: {average_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7771d775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495dd324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
